{
	"name": "kaggle1_entrenamiento_pablo_garcia",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "5678b2ad-58ca-4be7-a8a9-bfd4fb3d7ca3"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"source": [
					"# Primera entrega Kaggle\n",
					"\n",
					"**Pablo García Caballero**"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"Importamos librerias"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"import numpy as np\n",
					"import pickle\n",
					"import re\n",
					"\n",
					"# Transformación de datos\n",
					"from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder #, TargetEncoder\n",
					"#import category_encoders as ce\n",
					"from category_encoders import TargetEncoder\n",
					"\n",
					"from sklearn.impute import SimpleImputer\n",
					"\n",
					"# Modelos\n",
					"from sklearn.tree import DecisionTreeClassifier\n",
					"import lightgbm as lgb\n",
					"\n",
					"# Seleccion de variables y tuning de hiperparámetros\n",
					"from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
					"\n",
					"# Métricas para evaluar un modelo de clasificación\n",
					"from sklearn.metrics import classification_report, accuracy_score, precision_recall_curve, auc, roc_curve, roc_auc_score, average_precision_score, confusion_matrix\n",
					"\n",
					"# Librerías para visualización de resultados\n",
					"import matplotlib.pyplot as plt\n",
					"import seaborn as sns\n",
					"\n",
					"pd.set_option('display.max_columns', None)\n",
					"pd.set_option('display.max_rows', None)"
				],
				"execution_count": 1
			},
			{
				"cell_type": "markdown",
				"source": [
					"Definimos la función disponible en el campus para clasificar las columnas"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"def guess_type(column_name:str , df:pd.DataFrame, m=None, original_df=None) -> str:\n",
					"\n",
					"    if df[column_name].dtype == 'O':\n",
					"        return 'text'\n",
					"    try:\n",
					"        if m is not None and bool(m.get_all(name=column_name)):\n",
					"            return m.get_all(name=column_name).type[0]\n",
					"        elif m is not None and bool(m.get_all(name=column_name[:-2])) and original_df is not None:\n",
					"            #lets check if this is a date:\n",
					"            original_colname = column_name[:-2]\n",
					"            atype = original_df[original_colname].dtype\n",
					"            typ = str(atype)\n",
					"            if re.search(\"^date.\", typ):\n",
					"                return 'categorical'\n",
					"            if atype == 'O':\n",
					"                row_sample = original_df[original_colname].iloc[0]\n",
					"                if is_date(row_sample):\n",
					"                    return 'categorical'\n",
					"\n",
					"        #if isinstance(row_sample, float):\n",
					"        #    return 'numerical'\n",
					"        if df[column_name].dtype in ['float64', 'float32', 'float16']:\n",
					"            # we have to check if column was wrong catalogued as numerical\n",
					"            grouped = df[column_name].unique()\n",
					"            if len(grouped) < 10:\n",
					"                #check there are no decimals\n",
					"                for v in grouped:\n",
					"                    are_decimals = v - int(v)\n",
					"                    if are_decimals > 0.0:\n",
					"                        return 'numerical'\n",
					"                return 'categorical'\n",
					"            return 'numerical'\n",
					"\n",
					"        elif df[column_name].dtype in ['int64', 'int32', 'int16', 'int8']:\n",
					"            max = df[column_name].max()\n",
					"            min = df[column_name].min()\n",
					"            diff = max - min\n",
					"            diff2 = int(max) - int(min)\n",
					"            if diff == diff2:\n",
					"                if diff < 10:\n",
					"                    grouped = df[column_name].unique()\n",
					"                    if len(grouped)< 10:\n",
					"                        return 'categorical'\n",
					"            return \"numerical\"\n",
					"        else:\n",
					"            return \"categorical\"\n",
					"    except Exception as e:\n",
					"        return 'categorical'"
				],
				"execution_count": 2
			},
			{
				"cell_type": "markdown",
				"source": [
					"Carga de datos"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"dfTrain = pd.read_csv(\"MasterBI_Train.csv\", low_memory=False)\n",
					"label = \"HasDetections\""
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"dfTrain.head()"
				],
				"execution_count": 4
			},
			{
				"cell_type": "markdown",
				"source": [
					"**EDA**. En primer lugar, realizamos un analisis exploratorio del conjunto de datos. "
				]
			},
			{
				"cell_type": "code",
				"source": [
					"dfTrain.info()"
				],
				"execution_count": 5
			},
			{
				"cell_type": "markdown",
				"source": [
					"Agrupamos las columnas que sean identificadores para posteriormermente elimarlas del df, ya que no son utiles para el entramiento"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"id_colums = [\"MachineIdentifier\"]#, \"ProductName\", \"EngineVersion\", \"AppVersion\", \"AvSigVersion\"]\n",
					"dfTrain.drop(columns=id_colums, inplace=True)"
				],
				"execution_count": 6
			},
			{
				"cell_type": "markdown",
				"source": [
					"Convertimos a categoricas los campos que correspondan en función de la función guess_type"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"for i in dfTrain.columns:\n",
					"    print(f\"{i} = {guess_type(i, dfTrain)}\")\n",
					"    if guess_type(i, dfTrain) == \"categorical\":\n",
					"        dfTrain[i] = dfTrain[i].astype('category')\n",
					"        print(\"convertido\")\n",
					"    else:\n",
					"        print(\"no\")"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"source": [
					"columnas_cat = dfTrain.select_dtypes(include=[\"object\", \"category\"]).columns.to_list()\n",
					"columnas_num = dfTrain.select_dtypes(include=[\"float64\", \"int64\"]).columns.to_list()"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"source": [
					"print(columnas_cat)\n",
					"print(columnas_num)"
				],
				"execution_count": 9
			},
			{
				"cell_type": "markdown",
				"source": [
					"Eliminamos el label de nuestro conjunto de categóricas"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"if label in columnas_cat:\n",
					"    columnas_cat.remove(label)\n",
					"    print(\"Label borrado de las cat\")\n",
					"else:\n",
					"    columnas_num.remove(label)\n",
					"    print(\"Label borrado de las num\")"
				],
				"execution_count": 10
			},
			{
				"cell_type": "markdown",
				"source": [
					"Imputamos los nulos mediante la media para las numericas"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# esto esta mal , primero dividir\n",
					"\n",
					"imp_num = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
					"#dfTrain[columnas_num] = imp_num.fit_transform(dfTrain[columnas_num])"
				],
				"execution_count": 11
			},
			{
				"cell_type": "markdown",
				"source": [
					"Imputamos los nulos mediante la moda para las categoricas"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"imp_cat = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
					"#dfTrain[columnas_cat] = imp_cat.fit_transform(dfTrain[columnas_cat])"
				],
				"execution_count": 12
			},
			{
				"cell_type": "markdown",
				"source": [
					"Preparamos la codificación de variables"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"cat_num = columnas_cat+columnas_num \n",
					"dfTrain = dfTrain[cat_num+['HasDetections']]"
				],
				"execution_count": 14
			},
			{
				"cell_type": "code",
				"source": [
					"te = TargetEncoder()"
				],
				"execution_count": 13
			},
			{
				"cell_type": "markdown",
				"source": [
					"**Modelo**"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"Dividimos el df en train y test"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# X = dfTrain.drop('HasDetections', axis=1)\n",
					"# y = dfTrain['HasDetections']\n",
					"# X = dfTrain.drop(label, axis=1)\n",
					"# y = dfTrain[label]\n",
					"X = dfTrain.drop(label, axis=1)\n",
					"y = dfTrain[label]\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"X_train[columnas_num] = imp_num.fit_transform(X_train[columnas_num])\n",
					"X_train[columnas_cat] = imp_cat.fit_transform(X_train[columnas_cat])\n",
					"#X_train.isnull().sum()"
				],
				"execution_count": 15
			},
			{
				"cell_type": "code",
				"source": [
					"X_test[columnas_num] = imp_num.transform(X_test[columnas_num])\n",
					"X_test[columnas_cat] = imp_cat.transform(X_test[columnas_cat])\n",
					"#X_test.isnull().sum()"
				],
				"execution_count": 16
			},
			{
				"cell_type": "markdown",
				"source": [
					"Aplicamos el encoder"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"print(columnas_cat)\n",
					"print(columnas_num)"
				],
				"execution_count": 31
			},
			{
				"cell_type": "code",
				"source": [
					"dfX_train_prep = pd.DataFrame(X_train , columns=columnas)\n",
					"dfX_test_prep = pd.DataFrame(X_test , columns=columnas)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"X_train_prep = te.fit_transform(X_train[columnas_cat], y_train)\n",
					"X_test_prep = te.transform(X_test[columnas_cat])\n",
					"#X_train.isnull().sum()"
				],
				"execution_count": 17
			},
			{
				"cell_type": "code",
				"source": [
					"X_test[columnas_num] = imp_num.transform(X_test[columnas_num])\n",
					"X_test[columnas_cat] = imp_cat.transform(X_test[columnas_cat])\n",
					"#X_test.isnull().sum()"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"X_train_prep = te.fit_transform(X_train,y_train)\n",
					"\n",
					"#X_test_prep = te.transform(X_test)"
				],
				"execution_count": 19
			},
			{
				"cell_type": "code",
				"source": [
					"te.fit_transform(X_train, y_train)"
				],
				"execution_count": 19
			},
			{
				"cell_type": "code",
				"source": [
					"X_train_prep = te.transform(X_train)\n",
					"X_test_prep = te.transform(X_test)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# X_train_prep = te.fit_transform(X_train, y_train)\n",
					"# X_test_prep = te.fit_transform(X_test, y_test)\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"Convertimos a df de nuevo"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"columnas = dfTrain.columns.to_list()\n",
					"columnas.remove(label)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"dfX_train_prep = pd.DataFrame(X_train_prep , columns=columnas)\n",
					"dfX_test_prep = pd.DataFrame(X_test_prep , columns=columnas)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"Entrenamos el modelo"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"model = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
					"model.fit(dfX_train_prep, y_train)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"**Predición y evaluación**"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"prediciones = model.predict(X = dfX_train_prep, ) # , )\n",
					"pred_proba = model.predict_proba( X = dfX_train_prep)\n",
					"\n",
					"data = confusion_matrix(y_train, prediciones)\n",
					"\n",
					"print(\"Matriz de confusión\")\n",
					"plt.figure(figsize=(6,5))\n",
					"sns.set(font_scale=1.4)\n",
					"sns.heatmap(data, cmap=\"Blues\", annot=True, annot_kws={\"size\":12})"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"print(f\"Acurracy: {round(100*accuracy_score(y_train, prediciones),1)}% \\n\")\n",
					"print(classification_report(y_train, prediciones, digits=3, zero_division=True))"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"Curva ROC y AUX"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"fpr, tpr, _ = roc_curve(y_test, pred_proba[:,1])\n",
					"roc_auc = auc(fpr, tpr)\n",
					"\n",
					"plt.figure(figsize = (6,5))\n",
					"lw = 2\n",
					"plt.plot(fpr, tpr, color='darkorange',\n",
					"         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
					"plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
					"plt.xlim([0.0, 1.0])\n",
					"plt.ylim([0.0, 1.05])\n",
					"plt.xlabel('False Positive Rate')\n",
					"plt.ylabel('True Positive Rate')\n",
					"plt.title('Receiver operating characteristic example')\n",
					"plt.legend(loc=\"lower right\")\n",
					"plt.show()"
				],
				"execution_count": 18
			},
			{
				"cell_type": "markdown",
				"source": [
					"**Pase a producción**"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"Replicamos los pasos anteriores, pero sin dividir el df en test/train"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"dfTrainFull = pd.read_csv(\"MasterBI_Train.csv\", low_memory=False)\n",
					"label = \"HasDetections\""
				],
				"execution_count": 97
			},
			{
				"cell_type": "code",
				"source": [
					"id_colums = [\"MachineIdentifier\"]#, \"ProductName\", \"EngineVersion\", \"AppVersion\", \"AvSigVersion\"]\n",
					"dfTrainFull.drop(columns=id_colums, inplace=True)"
				],
				"execution_count": 98
			},
			{
				"cell_type": "code",
				"source": [
					"for i in dfTrainFull.columns:\n",
					"    print(f\"{i} = {guess_type(i, dfTrainFull)}\")\n",
					"    if guess_type(i, dfTrainFull) == \"categorical\":\n",
					"        dfTrainFull[i] = dfTrainFull[i].astype('category')\n",
					"        print(\"convertido\")\n",
					"    else:\n",
					"        print(\"no\")"
				],
				"execution_count": 99
			},
			{
				"cell_type": "code",
				"source": [
					"columnas_cat = dfTrainFull.select_dtypes(include=[\"object\", \"category\"]).columns.to_list()\n",
					"columnas_num = dfTrainFull.select_dtypes(include=[\"float64\", \"int64\"]).columns.to_list()"
				],
				"execution_count": 100
			},
			{
				"cell_type": "code",
				"source": [
					"columnas_cat.remove(label)"
				],
				"execution_count": 101
			},
			{
				"cell_type": "code",
				"source": [
					"imp_num = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
					"dfTrainFull[columnas_num] = imp_num.fit_transform(dfTrainFull[columnas_num])"
				],
				"execution_count": 102
			},
			{
				"cell_type": "code",
				"source": [
					"imp_cat = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
					"dfTrainFull[columnas_cat] = imp_cat.fit_transform(dfTrainFull[columnas_cat])"
				],
				"execution_count": 103
			},
			{
				"cell_type": "code",
				"source": [
					"cat_num = columnas_cat+columnas_num \n",
					"dfTrainFull = dfTrainFull[cat_num+['HasDetections']]"
				],
				"execution_count": 104
			},
			{
				"cell_type": "code",
				"source": [
					"te = TargetEncoder()"
				],
				"execution_count": 105
			},
			{
				"cell_type": "code",
				"source": [
					"X = dfTrainFull.drop(label, axis=1)\n",
					"y = dfTrainFull[label]"
				],
				"execution_count": 106
			},
			{
				"cell_type": "code",
				"source": [
					"X_train_prep = te.fit_transform(X, y)"
				],
				"execution_count": 107
			},
			{
				"cell_type": "code",
				"source": [
					"columnas = dfTrain.columns.to_list()\n",
					"columnas.remove(label)"
				],
				"execution_count": 108
			},
			{
				"cell_type": "code",
				"source": [
					"dfX_train_prep = pd.DataFrame(X_train_prep , columns=columnas)"
				],
				"execution_count": 110
			},
			{
				"cell_type": "code",
				"source": [
					"model = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
					"model.fit(dfX_train_prep, y)"
				],
				"execution_count": 111
			},
			{
				"cell_type": "markdown",
				"source": [
					"Por último, utilizando las funcionalidades de la librería pickle, guardamos todo aquello ques nos va a hacer falta para la inferencia con los datos de test"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Modelo\n",
					"with open(\"output/modelo.pkl\", \"wb\") as c:\n",
					"    pickle.dump(model, c)\n",
					"\n",
					"# Transformación\n",
					"with open(\"output/num_imputer.pkl\", \"wb\") as c:\n",
					"    pickle.dump(imp_num, c)\n",
					"with open(\"output/cat_imputer.pkl\", \"wb\") as c:\n",
					"    pickle.dump(imp_cat, c)\n",
					"with open(\"output/encoder.pkl\", \"wb\") as c:\n",
					"    pickle.dump(te, c)\n",
					"\n",
					"# Lista de todas columnas\n",
					"todas_columnas = dfTrainFull.columns.to_list()\n",
					"with open(\"output/columns.pkl\", \"wb\") as c:\n",
					"    pickle.dump(todas_columnas, c)\n",
					"\n",
					"# Columnas Cat\n",
					"with open(\"output/cat_columns.pkl\", \"wb\") as c:\n",
					"     pickle.dump(columnas_cat, c)\n",
					"\n",
					"# Columnas Num\n",
					"with open(\"output/num_columns.pkl\", \"wb\") as c:\n",
					"     pickle.dump(columnas_num, c)"
				],
				"execution_count": null
			}
		]
	}
}