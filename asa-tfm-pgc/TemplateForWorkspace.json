{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Nombre del área de trabajo",
			"defaultValue": "asa-tfm-pgc"
		},
		"asa-tfm-pgc-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Cadena protegida para \"connectionString\"de \"asa-tfm-pgc-WorkspaceDefaultSqlServer\"",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:asa-tfm-pgc.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"ls_ADLG2_Bronze_Landing_accountKey": {
			"type": "secureString",
			"metadata": "Cadena protegida para \"accountKey\"de \"ls_ADLG2_Bronze_Landing\""
		},
		"ls_COLI_ERP_password": {
			"type": "secureString",
			"metadata": "Cadena protegida para \"password\"de \"ls_COLI_ERP\""
		},
		"asa-tfm-pgc-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://datalake1pgc.dfs.core.windows.net"
		},
		"ls_ADLG2_Bronze_Landing_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://datalake1pgc.dfs.core.windows.net/"
		},
		"ls_COLI_ERP_properties_typeProperties_server": {
			"type": "string",
			"defaultValue": "@{linkedService().NombreServidor}"
		},
		"ls_COLI_ERP_properties_typeProperties_database": {
			"type": "string",
			"defaultValue": "@{linkedService().NombreBaseDatos}"
		},
		"ls_COLI_ERP_properties_typeProperties_userName": {
			"type": "string",
			"defaultValue": "sa"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/1 - SqlToLanding')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "List of Tables to Load",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "Clean Landing",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": false,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"dataset": {
								"referenceName": "csvConfiguration",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "Save Landing Files",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "List of Tables to Load",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('List of tables to load').output.value",
								"type": "Expression"
							},
							"isSequential": false,
							"activities": [
								{
									"name": "Active For Load",
									"type": "IfCondition",
									"dependsOn": [],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@not(equals(trim(item().Load), 'N'))",
											"type": "Expression"
										},
										"ifTrueActivities": [
											{
												"name": "Carga Landing",
												"type": "Copy",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 0,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"source": {
														"type": "SqlServerSource",
														"sqlReaderQuery": {
															"value": "SELECT *, @{formatDateTime(pipeline().TriggerTime,'yyyyMMdd')} AS fechaCarga, '@{pipeline().RunId}' AS pipelineID \nFROM @{item().SchemaName}.@{item().TableName} \nWHERE @{item().IncrementalColumn} >= CAST(CAST('@{item().UpdateDate}' AS nvarchar) AS datetime2);",
															"type": "Expression"
														},
														"queryTimeout": "02:00:00",
														"partitionOption": "None"
													},
													"sink": {
														"type": "ParquetSink",
														"storeSettings": {
															"type": "AzureBlobFSWriteSettings",
															"copyBehavior": "FlattenHierarchy"
														},
														"formatSettings": {
															"type": "ParquetWriteSettings"
														}
													},
													"enableStaging": false,
													"parallelCopies": 1,
													"dataIntegrationUnits": 4,
													"translator": {
														"type": "TabularTranslator",
														"typeConversion": true,
														"typeConversionSettings": {
															"allowDataTruncation": true,
															"treatBooleanAsNumber": false
														}
													}
												},
												"inputs": [
													{
														"referenceName": "dsSQLGenerico",
														"type": "DatasetReference",
														"parameters": {
															"NombreServidor": "@item().ServerName",
															"NombreBD": "@item().DataBaseName",
															"NombreEsquema": "@item().SchemaName",
															"NombreTabla": "@item().TableName",
															"FechaActualizacion": "@item().UpdateDate",
															"ColumnaIncremental": {
																"value": "@item().IncrementalColumn",
																"type": "Expression"
															}
														}
													}
												],
												"outputs": [
													{
														"referenceName": "dsParquetRaw",
														"type": "DatasetReference",
														"parameters": {
															"NombreFichero": "@concat( item().FileName, '_', formatDateTime(utcnow(), 'yyyyMMdd'),'.', item().Format)"
														}
													}
												]
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "Clean Landing",
						"type": "Delete",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "dsParquetRaw",
								"type": "DatasetReference",
								"parameters": {
									"NombreFichero": "*"
								}
							},
							"logStorageSettings": {
								"linkedServiceName": {
									"referenceName": "ls_ADLG2_Bronze_Landing",
									"type": "LinkedServiceReference"
								},
								"path": "mdw/bronze/Logs"
							},
							"enableLogging": true,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"wildcardFileName": "*",
								"enablePartitionDiscovery": false
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-09-16T00:20:34Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/csvConfiguration')]",
				"[concat(variables('workspaceId'), '/datasets/dsParquetRaw')]",
				"[concat(variables('workspaceId'), '/linkedServices/ls_ADLG2_Bronze_Landing')]",
				"[concat(variables('workspaceId'), '/datasets/dsSQLGenerico')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/1 - SqlToLanding_old')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Listado tablas a cargar",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": false,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"dataset": {
								"referenceName": "csvConfiguration",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Listado tablas a cargar",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Listado tablas a cargar').output.value",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "Copiar Tablas de Configuracion",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "SqlServerSource",
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"sink": {
											"type": "ParquetSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "ParquetWriteSettings"
											}
										},
										"enableStaging": false,
										"parallelCopies": 1,
										"dataIntegrationUnits": 4,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "dsSQLGenerico",
											"type": "DatasetReference",
											"parameters": {
												"NombreServidor": {
													"value": "@item().ServerName",
													"type": "Expression"
												},
												"NombreBD": {
													"value": "@item().DataBaseName",
													"type": "Expression"
												},
												"NombreEsquema": {
													"value": "@item().SchemaName",
													"type": "Expression"
												},
												"NombreTabla": {
													"value": "@item().TableName",
													"type": "Expression"
												},
												"FechaActualizacion": {
													"value": "@item().UpdateDate",
													"type": "Expression"
												},
												"ColumnaIncremental": {
													"value": "@item().IncrementalColumn",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "dsParquetRaw",
											"type": "DatasetReference",
											"parameters": {
												"NombreFichero": {
													"value": "@concat( item().FileName, '_', formatDateTime(utcnow(), 'yyyyMMdd'),'.', item().Format)\n",
													"type": "Expression"
												}
											}
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-09-15T16:45:27Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/csvConfiguration')]",
				"[concat(variables('workspaceId'), '/datasets/dsSQLGenerico')]",
				"[concat(variables('workspaceId'), '/datasets/dsParquetRaw')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/2 - BronzeToSilver')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "UPSERT Silver",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata Landing",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata Landing').output.childItems",
								"type": "Expression"
							},
							"isSequential": false,
							"activities": [
								{
									"name": "Clean Landing",
									"type": "Delete",
									"dependsOn": [
										{
											"activity": "LandingToProcessed",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataset": {
											"referenceName": "dsParquetRaw",
											"type": "DatasetReference",
											"parameters": {
												"NombreFichero": {
													"value": "@item().name",
													"type": "Expression"
												}
											}
										},
										"enableLogging": false,
										"storeSettings": {
											"type": "AzureBlobFSReadSettings",
											"recursive": false,
											"enablePartitionDiscovery": false
										}
									}
								},
								{
									"name": "LandingToProcessed",
									"type": "Copy",
									"dependsOn": [
										{
											"activity": "MergeBronzeToSilver",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "ParquetSource",
											"storeSettings": {
												"type": "AzureBlobFSReadSettings",
												"recursive": false,
												"enablePartitionDiscovery": false
											},
											"formatSettings": {
												"type": "ParquetReadSettings"
											}
										},
										"sink": {
											"type": "ParquetSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "ParquetWriteSettings"
											}
										},
										"enableStaging": false,
										"parallelCopies": 1,
										"dataIntegrationUnits": 4,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "dsParquetRaw",
											"type": "DatasetReference",
											"parameters": {
												"NombreFichero": {
													"value": "@item().name",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "dsParquetProcessed",
											"type": "DatasetReference",
											"parameters": {
												"NombreFichero": {
													"value": "@item().name",
													"type": "Expression"
												},
												"NombreCarpeta": {
													"value": "@concat(\n    substring(item().name, 0, indexOf(item().name, '_')), \n    '/', \n    substring(item().name, add(indexOf(item().name, '_'), 1), 4), \n    '/', \n    substring(item().name, add(indexOf(item().name, '_'), 5), 2), \n    '/'\n)\n",
													"type": "Expression"
												}
											}
										}
									]
								},
								{
									"name": "MergeBronzeToSilver",
									"type": "SynapseNotebook",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"notebook": {
											"referenceName": "MergeLandingFilesToSilver",
											"type": "NotebookReference"
										},
										"parameters": {
											"data_lake_container": {
												"value": "abfss://mdw@datalake1pgc.dfs.core.windows.net",
												"type": "string"
											},
											"bronze_folder": {
												"value": "bronze/Landing",
												"type": "string"
											},
											"table_name": {
												"value": {
													"value": "@substring(item().name, 0, indexOf(item().name, '_'))",
													"type": "Expression"
												},
												"type": "string"
											},
											"silver_folder": {
												"value": "silver",
												"type": "string"
											},
											"source_wildcard": {
												"value": {
													"value": "@concat(substring(item().name, 0, indexOf(item().name, '_')), '*.parquet')",
													"type": "Expression"
												},
												"type": "string"
											},
											"key_columns_str": {
												"value": {
													"value": "@concat('id',substring(item().name, 0, indexOf(item().name, '_')))",
													"type": "Expression"
												},
												"type": "string"
											}
										},
										"snapshot": true,
										"sparkPool": {
											"referenceName": "sparkTFM",
											"type": "BigDataPoolReference"
										},
										"executorSize": "Small",
										"conf": {
											"spark.dynamicAllocation.enabled": false,
											"spark.dynamicAllocation.minExecutors": 2,
											"spark.dynamicAllocation.maxExecutors": 2
										},
										"driverSize": "Small",
										"numExecutors": 2
									}
								}
							]
						}
					},
					{
						"name": "Get Metadata Landing",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "dsRawEntidades",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "ParquetReadSettings"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/dsRawEntidades')]",
				"[concat(variables('workspaceId'), '/datasets/dsParquetRaw')]",
				"[concat(variables('workspaceId'), '/datasets/dsParquetProcessed')]",
				"[concat(variables('workspaceId'), '/notebooks/MergeLandingFilesToSilver')]",
				"[concat(variables('workspaceId'), '/bigDataPools/sparkTFM')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/3 - SilverToSCD2')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Lista ficheros Landing",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "dsRawEntidades",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "ParquetReadSettings"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-09-14T15:15:28Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/dsRawEntidades')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/4 - SilverToGold')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Lista ficheros Landing",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "dsRawEntidades",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "ParquetReadSettings"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-09-14T15:17:01Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/dsRawEntidades')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ETL')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "1",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "1 - SqlToLanding",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "3",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "1_copy1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "3 - SilverToSCD2",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "4",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "3",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "4 - SilverToGold",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "1_copy1",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "2 - BronzeToSilver",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-09-15T16:46:15Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/1 - SqlToLanding')]",
				"[concat(variables('workspaceId'), '/pipelines/3 - SilverToSCD2')]",
				"[concat(variables('workspaceId'), '/pipelines/4 - SilverToGold')]",
				"[concat(variables('workspaceId'), '/pipelines/2 - BronzeToSilver')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/csvConfiguration')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_ADLG2_Bronze_Landing",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "ConfiguracionOrigenes.csv",
						"folderPath": "bronze/Configuration",
						"fileSystem": "mdw"
					},
					"columnDelimiter": ";",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "ServerName;DataBaseName;SchemaName;TableName;PathName;FileName;Load",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ls_ADLG2_Bronze_Landing')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dsParquetProcessed')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_ADLG2_Bronze_Landing",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"NombreFichero": {
						"type": "string"
					},
					"NombreCarpeta": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().NombreFichero",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@concat('bronze/Processed/', dataset().NombreCarpeta)",
							"type": "Expression"
						},
						"fileSystem": "mdw"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ls_ADLG2_Bronze_Landing')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dsParquetRaw')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_ADLG2_Bronze_Landing",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"NombreFichero": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().NombreFichero",
							"type": "Expression"
						},
						"folderPath": "bronze/Landing",
						"fileSystem": "mdw"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ls_ADLG2_Bronze_Landing')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dsRawEntidades')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_ADLG2_Bronze_Landing",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "bronze/Landing",
						"fileSystem": "mdw"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ls_ADLG2_Bronze_Landing')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dsSQLGenerico')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_COLI_ERP",
					"type": "LinkedServiceReference",
					"parameters": {
						"NombreServidor": {
							"value": "@dataset().NombreServidor",
							"type": "Expression"
						},
						"NombreBaseDatos": {
							"value": "@dataset().NombreBD",
							"type": "Expression"
						}
					}
				},
				"parameters": {
					"NombreServidor": {
						"type": "string"
					},
					"NombreBD": {
						"type": "string"
					},
					"NombreEsquema": {
						"type": "string"
					},
					"NombreTabla": {
						"type": "string"
					},
					"FechaActualizacion": {
						"type": "string"
					},
					"ColumnaIncremental": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "SqlServerTable",
				"schema": [],
				"typeProperties": {
					"schema": {
						"value": "@dataset().NombreEsquema",
						"type": "Expression"
					},
					"table": {
						"value": "@dataset().NombreTabla",
						"type": "Expression"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ls_COLI_ERP')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/asa-tfm-pgc-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('asa-tfm-pgc-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/asa-tfm-pgc-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('asa-tfm-pgc-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ls_ADLG2_Bronze_Landing')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('ls_ADLG2_Bronze_Landing_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('ls_ADLG2_Bronze_Landing_accountKey')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ls_COLI_ERP')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"NombreServidor": {
						"type": "string"
					},
					"NombreBaseDatos": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "SqlServer",
				"typeProperties": {
					"server": "[parameters('ls_COLI_ERP_properties_typeProperties_server')]",
					"database": "[parameters('ls_COLI_ERP_properties_typeProperties_database')]",
					"encrypt": "mandatory",
					"trustServerCertificate": true,
					"authenticationType": "SQL",
					"userName": "[parameters('ls_COLI_ERP_properties_typeProperties_userName')]",
					"password": {
						"type": "SecureString",
						"value": "[parameters('ls_COLI_ERP_password')]"
					}
				},
				"connectVia": {
					"referenceName": "IR-Coli-ERP",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/IR-Coli-ERP')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/IR-Coli-ERP')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "SelfHosted",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Configure SilverlessSTG')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE MASTER KEY ENCRYPTION BY PASSWORD = 'tfmVerne.'\nCREATE DATABASE SCOPED CREDENTIAL ManagedIdentity WITH IDENTITY = 'Managed Identity' GO\n\nCREATE EXTERNAL DATA SOURCE datalake1pgc\nWITH (\n    \n    LOCATION = 'abfss://mdw@datalake1pgc.dfs.core.windows.net',\n    CREDENTIAL = ManagedIdentity\n);\n\nCREATE SCHEMA silver AUTHORIZATION dbo;\nCREATE SCHEMA dim AUTHORIZATION dbo;\nCREATE SCHEMA fact AUTHORIZATION dbo;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SCD2 Load Silver CETAs')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "-- CREATE MASTER KEY ENCRYPTION BY PASSWORD = 'tfmVerne.'\n-- CREATE DATABASE SCOPED CREDENTIAL ManagedIdentity WITH IDENTITY = 'Managed Identity' GO\n-- CREATE EXTERNAL DATA SOURCE datalake1pgc WITH ( TYPE = HADOOP, LOCATION =  'abfss://mdw@datalakefrancepgc.dfs.core.windows.net', CREDENTIAL = ManagedIdentity )\n-- 'abfss://mdw@datalake1pgc.dfs.core.windows.net'\n\n-- CREATE EXTERNAL DATA SOURCE datalake1pgc\n-- WITH (\n    \n--     LOCATION = 'abfss://mdw@datalake1pgc.dfs.core.windows.net',\n--     CREDENTIAL = ManagedIdentity\n-- );\n\n-- CREATE SCHEMA silver AUTHORIZATION dbo;\n-- CREATE SCHEMA dim AUTHORIZATION dbo;\n-- CREATE SCHEMA fact AUTHORIZATION dbo;\n\n-- CREATE EXTERNAL FILE FORMAT ParquetFileFormat WITH (FORMAT_TYPE = PARQUET, DATA_COMPRESSION = 'org.apache.hadoop.io.compress.SnappyCodec')\n\n--DROP EXTERNAL TABLE [dim].[Articles]\n\n-- CREATE  EXTERNAL TABLE [silver].[TestFechas]\n-- (\n-- \t idFechas INT,\n--      ClaveFecha INT,\n--      Fecha datetime2(7),\n--      Mes VARCHAR(64),\n--      NumeroMes INT,\n--      Año INT,\n--      NumeroSemana INT,\n--      DiaSemana VARCHAR(64),\n--      NumeroDiaSemana INT,\n--      DiaAño INT,\n--      Trimestre INT,\n--      Cuatrimestre INT,\n--      Semestre INT,\n--      fechaActualizacion INT,\n--      D_valid INT null,\n--     ID_Deleted INT null,\n--     From_date datetime2(7)null,\n--     End_date datetime2(7) null  \n-- )\n-- WITH\n-- (\n-- \tLOCATION = 'gold/TestDimDate', \n-- \tDATA_SOURCE = datalakefrancepgc,\n-- \tFILE_FORMAT = ParquetFileFormat\n-- ) AS \n-- SELECT \n--     idFechas,\n--     ClaveFecha,\n--     Fecha,\n--     Mes,\n--     NumeroMes,\n--     Año,\n--     NumeroSemana,\n--     DiaSemana,\n--     NumeroDiaSemana,\n--     DiaAño,\n--     Trimestre,\n--     Cuatrimestre,\n--     Semestre,\n--     fechaActualizacion,\n--     1 ID_valid,\n--     0 ID_Deleted,\n--     GETDATE() AS From_date,\n--     NULL AS End_date \n-- FROM\n-- [Silverless].[dbo].[vw_dim_Fechas]\n\n\nCREATE  EXTERNAL TABLE [dim].[Articles]\n(\n\tidArticles INT,\n    name NVARCHAR(256),\n    description NVARCHAR(256),\n    externalcode NVARCHAR(64),\n    size NVARCHAR(64),\n    numSize INT,\n    colour NVARCHAR(128),\n    category NVARCHAR(128),\n    codLine NVARCHAR(128),\n    line NVARCHAR(128),\n    season NVARCHAR(64),\n    ID_valid INT null,\n    ID_Deleted INT null,\n    From_date datetime2(7)null,\n    End_date datetime2(7) null  \n)\nWITH\n(\n\tLOCATION = 'gold/Dimensions/Articles', \n\tDATA_SOURCE = datalakefrancepgc,\n\tFILE_FORMAT = ParquetFileFormat\n) AS \nSELECT \n[idArticles]\n,[name]\n,[description]\n,[externalCode]\n,[size]\n,[numSize]\n,[colour]\n,[category]\n,[codLine]\n,[line]\n,[season]\n--,[loadDate]\n--,[deltaDate]\n,1 ID_valid\n,0 ID_Deleted\n,GETDATE() AS From_date\n,NULL AS End_date \nFROM\n[silverlessSTG].[etl].[vw_dim_Articles]\n\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "default",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SCD2 Load Silver Warehouse CETAs')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "-- CREATE MASTER KEY ENCRYPTION BY PASSWORD = 'tfmVerne.'\n-- CREATE DATABASE SCOPED CREDENTIAL ManagedIdentity WITH IDENTITY = 'Managed Identity' GO\n-- CREATE EXTERNAL DATA SOURCE datalake1pgc WITH ( TYPE = HADOOP, LOCATION =  'abfss://mdw@datalakefrancepgc.dfs.core.windows.net', CREDENTIAL = ManagedIdentity )\n-- 'abfss://mdw@datalake1pgc.dfs.core.windows.net'\n\n-- CREATE EXTERNAL DATA SOURCE datalake1pgc\n-- WITH (\n    \n--     LOCATION = 'abfss://mdw@datalake1pgc.dfs.core.windows.net',\n--     CREDENTIAL = ManagedIdentity\n-- );\n\n-- CREATE SCHEMA silver AUTHORIZATION dbo;\n-- CREATE SCHEMA dim AUTHORIZATION dbo;\n-- CREATE SCHEMA fact AUTHORIZATION dbo;\nCREATE  EXTERNAL TABLE [dim].[Warehouse]\nWITH\n(\n\tLOCATION = 'gold/Dimensions/Warehouse', \n\tDATA_SOURCE = datalake1pgc,\n\tFILE_FORMAT = ParquetFileFormat\n) AS \nSELECT \nROW_NUMBER () OVER (ORDER BY idWarehouse) idSkWarehouse,\nw.*  --, CAST(CAST(deltaDate as nvarchar) AS datetime2)\n,CAST('1990-01-01' AS datetime2) AS fromDate\n,NULL AS toDate \n,1 isCurrent\nFROM\n[SilverlessSTG].[etl].[vw_dim_Warehouse] as w",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SilverlessSTG",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Script Dimensiones Silver')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "---------------\n-- Dim Date --\n---------------\nGO\nCREATE OR ALTER VIEW [etl].[vw_dim_Date] AS \nSELECT  idFechas AS idDate,\n        ClaveFecha AS dateKey,\n        Fecha AS date,\n        COALESCE(Mes, 'D')  AS month,\n        COALESCE(NumeroMes, -1)  AS monthNumber,\n        COALESCE(Ano, -1)  AS year,\n        COALESCE(NumeroSemana, -1)  AS weekNumber,\n        COALESCE(DiaSemana, 'D') AS dayWeek,\n        COALESCE(NumeroDiaSemana, -1)  AS dayWeekNumber,\n        COALESCE(DiaAno, -1) AS yearDay,\n        COALESCE(Trimestre, -1)  AS quarter,\n        COALESCE(Cuatrimestre, -1)  AS quadrimester,\n        CASE WHEN Cuatrimestre IN (1,2) THEN 1\n            WHEN Cuatrimestre IN (2,4) THEN 2\n            ELSE -1 END AS semester,\n        fechaCarga AS loadDate,\n        fechaDelta AS deltaDate\nFROM [default].[dbo].[fechas]\n\n------------------\n-- Dim Articles --\n------------------\nGO\nCREATE OR ALTER VIEW [etl].[vw_dim_Articles] AS\nSELECT  idArticulos AS idArticles,\n        COALESCE(nombre, 'D') AS name,\n        COALESCE(descripcion, 'D') AS description,\n        COALESCE(codigoReferencia, 'D') AS externalCode,\n        COALESCE(t.talla, 'D') AS size,\n        COALESCE( t.numeroTalla, -1) AS numSize,\n        COALESCE(co.color, 'D') AS colour,\n        COALESCE(ca.categoria, 'D') AS category,\n        COALESCE(l.codigoLinea, 'D') AS codLine,\n        COALESCE(l.Linea, 'D') AS line, \n        CASE WHEN SUBSTRING(CAST(a.fechaCarga AS nvarchar),5,2) IN (4,5,6,7,8,9) THEN 'PV'+CAST(a.idTemporada AS nvarchar)\n        ELSE 'OI'+CAST(idTemporada AS nvarchar)\n        END AS season,\n        a.fechaCarga AS loadDate,\n        a.fechaDelta AS deltaDate\nFROM [default].[dbo].[articulos] AS a\nLEFT JOIN [default].[dbo].[talla] AS t\n    ON t.idTalla = a.idTalla\nLEFT JOIN [default].[dbo].[color] AS co\n   ON co.idColor = a.idColor\nLEFT JOIN [default].[dbo].[categoria] AS ca\n    ON ca.idCategoria = a.idCategoria\nLEFT JOIN [default].[dbo].[Linea] AS l\n    ON l.idLinea = a.idLinea\nwhere a.fechaDelta <> 20241009\n-------------------\n-- Dim Warehouse --\n-------------------\nGO\nCREATE OR ALTER VIEW [etl].[vw_dim_Warehouse] AS\nSELECT  idAlmacenes AS idWarehouse,\n        COALESCE(a.Nombre, 'D') AS warehouse,\n        COALESCE(a.codigoAlmacen, 'D') AS externalCode,\n        COALESCE(p.codigoPais, 'D') AS countryCode, \n        COALESCE(p.nombre, 'D') AS country,\n        COALESCE(a.ciudad, 'D') AS city,\n        COALESCE(a.Direccion, 'D') AS address,\n        COALESCE(a.descripcion, 'D') AS description,\n        a.fechaCarga AS loadDate,\n        a.fechaDelta AS deltaDate\nFROM [default].[dbo].[almacenes] AS a\nLEFT JOIN [default].[dbo].[pais] AS p\n    ON p.idpais = a.idPais\n    WHERE a.fechaDelta <> 20241011\nUNION \nselect 4,'Almacen Este','IT8','ES','Spain','Valencia','Calle Este 321','Almacén especializado en logística',20241010,20241010\n\n\n---------------------\n-- Dim Postal Code --\n---------------------\nGO\nCREATE OR ALTER VIEW [etl].[vw_dim_PostalCodes] AS\nSELECT *\nFROM [default].[dbo].[codigoPostal]\n\n------------------\n-- Dim Currency --\n------------------\nGO\nCREATE OR ALTER VIEW [etl].[vw_dim_Currency] AS\nSELECT *\nFROM [default].[dbo].[divisa]\n\n---------------\n-- Dim Hours --\n---------------\nGO\nCREATE OR ALTER VIEW [etl].[vw_dim_Hours] AS\nSELECT *\nFROM [default].[dbo].[horas]\n\n----------------\n-- Dim Tariff --\n----------------\nGO\nCREATE OR ALTER VIEW [etl].[vw_dim_Tarriff] AS\nSELECT *\nFROM [default].[dbo].[tarifa]\n\n------------------------\n-- Dim Operation Type --\n------------------------\nGO\nCREATE OR ALTER VIEW [etl].[vw_dim_OperationType] AS\nSELECT *\nFROM [default].[dbo].[tipoOperacion]\n\n\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SilverlessSTG",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/MergeLandingFilesToSilver')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkTFM",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "c3de3cf3-3147-4236-a81f-46c4ecdffd44"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/7e84f9f8-73c5-4e82-9296-f2f3c4838394/resourceGroups/RG-TFM_MasterVerne_PGC/providers/Microsoft.Synapse/workspaces/asa-tfm-pgc/bigDataPools/sparkTFM",
						"name": "sparkTFM",
						"type": "Spark",
						"endpoint": "https://asa-tfm-pgc.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkTFM",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"# # path of the data lake container (bronze and silver for this example)\r\n",
							"# data_lake_container = 'abfss://mdw@datalake1pgc.dfs.core.windows.net'\r\n",
							"# # The ingestion folder where your parquet file are located\r\n",
							"# bronze_folder = 'bronze/Landing'\r\n",
							"# # The silver folder where your Delta Tables will be stored\r\n",
							"# silver_folder = 'silver'\r\n",
							"# # The name of the table\r\n",
							"# table_name = 'color'\r\n",
							"# # The wildcard filter used within the bronze folder to find files\r\n",
							"# source_wildcard = 'color*.parquet'\r\n",
							"# # A comma separated string of one or more key columns (for the merge)\r\n",
							"# key_columns_str = 'idColor'"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"**Carga de ficheros parquet Landing sobre tablas Delta capa Silver**"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Import modules\r\n",
							"from delta.tables import DeltaTable\r\n",
							"from delta.tables import *\r\n",
							"from pyspark.sql.functions import when, lit, current_date, date_format\r\n",
							"from pyspark.sql import SparkSession"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Prueba::\r\n",
							"\r\n",
							"# Supongamos que tienes las variables necesarias\r\n",
							"# Fecha actual en formato yyyymmdd\r\n",
							"fecha_delta = date_format(current_date(), 'yyyyMMdd')\r\n",
							"#fecha_delta = '20241011'\r\n",
							"# Convert comma separated string with keys to array\r\n",
							"key_columns = key_columns_str.split(',')\r\n",
							"\r\n",
							"# Convert array with keys to where-clause for merge statement\r\n",
							"conditions_list = [f\"existing.{key}=updates.{key}\" for key in key_columns]\r\n",
							"\r\n",
							"# Determine path of source files from ingest layer\r\n",
							"source_path = data_lake_container + '/' + bronze_folder + '/' + source_wildcard\r\n",
							"\r\n",
							"# Determine path of Delta Lake Table \r\n",
							"delta_table_path = data_lake_container + '/' + silver_folder + '/' + table_name\r\n",
							"\r\n",
							"# Read file(s) in spark data frame\r\n",
							"sdf = spark.read.format('parquet').option(\"recursiveFileLookup\", \"true\").load(source_path)\r\n",
							"\r\n",
							"# Check countRows > 0 - Stop Notebook \r\n",
							"# CREAR DELTA TABLE DE COLOR\r\n",
							"\r\n",
							"if sdf.count() == 0:\r\n",
							"    print(\"no procesar\")\r\n",
							"else:\r\n",
							"    # Eliminar las columnas que no se desean\r\n",
							"    sdf = sdf.drop(\"fechaActualizacion\", \"pipelineID\")\r\n",
							"\r\n",
							"    # Check if the Delta Table exists\r\n",
							"    if DeltaTable.isDeltaTable(spark, delta_table_path):\r\n",
							"        # Read the existing Delta Table\r\n",
							"        delta_table = DeltaTable.forPath(spark, delta_table_path)\r\n",
							"\r\n",
							"        # Get the schema of the existing Delta table\r\n",
							"        existing_columns = delta_table.toDF().columns\r\n",
							"        \r\n",
							"        # Añadir columna fechaDelta al DataFrame\r\n",
							"        sdf = sdf.withColumn(\"fechaDelta\", lit(fecha_delta))\r\n",
							"\r\n",
							"        # Crear el conjunto de actualizaciones excluyendo 'fechaCarga'\r\n",
							"        update_set = {f\"existing.{col}\": f\"updates.{col}\" for col in existing_columns if col != 'fechaCarga'}\r\n",
							"\r\n",
							"        # Merge new data into existing table\r\n",
							"        delta_table.alias(\"existing\").merge(\r\n",
							"            source=sdf.alias(\"updates\"),\r\n",
							"            condition=\" AND \".join(conditions_list)\r\n",
							"        ).whenMatchedUpdate(\r\n",
							"            condition=\" OR \".join([f\"existing.{col} != updates.{col}\" for col in existing_columns if col not in ('fechaCarga', 'fechaDelta')]),\r\n",
							"            set={\r\n",
							"                \"fechaCarga\": \"updates.fechaCarga\",  # Usar fechaCarga del DataFrame\r\n",
							"                \"fechaDelta\": \"updates.fechaDelta\",  # Usar fechaDelta del DataFrame\r\n",
							"                **{f\"existing.{col}\": f\"updates.{col}\" for col in existing_columns if col not in ('fechaCarga', 'fechaDelta')}  # Incluir otros campos\r\n",
							"            }\r\n",
							"        ).whenNotMatchedInsert(\r\n",
							"            values={\r\n",
							"                \"fechaCarga\": \"updates.fechaCarga\",  # Usar fechaCarga del DataFrame\r\n",
							"                \"fechaDelta\": fecha_delta,  # Establecer fechaDelta al insertar\r\n",
							"                **{f\"{col}\": f\"updates.{col}\" for col in existing_columns if col not in ('fechaCarga', 'fechaDelta')}  # Incluir otros campos\r\n",
							"            }\r\n",
							"        ).execute()\r\n",
							"    else:\r\n",
							"        # Crear nueva tabla Delta con nuevos datos, incluyendo la columna fechaDelta\r\n",
							"        sdf = sdf.withColumn(\"fechaCarga\", sdf.fechaCarga)  # Mantener fechaCarga del DataFrame\r\n",
							"        sdf = sdf.withColumn(\"fechaDelta\", lit(fecha_delta))  # Establecer fechaDelta al crear la tabla\r\n",
							"        sdf.write.format('delta').save(delta_table_path)\r\n",
							"\r\n",
							"    spark.sql(f'CREATE TABLE IF NOT EXISTS default.{table_name} USING DELTA LOCATION \\'{delta_table_path}\\'')"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"**Crear manualmente Delta Tables**"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# source_path = data_lake_container + '/' + bronze_folder + '/' + source_wildcard\r\n",
							"\r\n",
							"# # Determine path of Delta Lake Table \r\n",
							"# delta_table_path = data_lake_container + '/' + silver_folder + '/' + table_name\r\n",
							"# #spark.sql(f'DROP TABLE default.color')\r\n",
							"# spark.sql(f'CREATE TABLE IF NOT EXISTS default.{table_name} USING DELTA LOCATION \\'{delta_table_path}\\'')"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# ### Copia:\r\n",
							"\r\n",
							"# # Supongamos que tienes las variables necesarias\r\n",
							"# # Fecha actual en formato yyyymmdd\r\n",
							"# fecha_delta = date_format(current_date(), 'yyyyMMdd')\r\n",
							"# #fecha_delta = '20241011'\r\n",
							"# # Convert comma separated string with keys to array\r\n",
							"# key_columns = key_columns_str.split(',')\r\n",
							"\r\n",
							"# # Convert array with keys to where-clause for merge statement\r\n",
							"# conditions_list = [f\"existing.{key}=updates.{key}\" for key in key_columns]\r\n",
							"\r\n",
							"# # Determine path of source files from ingest layer\r\n",
							"# source_path = data_lake_container + '/' + bronze_folder + '/' + source_wildcard\r\n",
							"\r\n",
							"# # Determine path of Delta Lake Table \r\n",
							"# delta_table_path = data_lake_container + '/' + silver_folder + '/' + table_name\r\n",
							"\r\n",
							"# # Read file(s) in spark data frame\r\n",
							"# sdf = spark.read.format('parquet').option(\"recursiveFileLookup\", \"true\").load(source_path)\r\n",
							"\r\n",
							"# # Check countRows > 0 - Stop Notebook \r\n",
							"# # CREAR DELTA TABLE DE COLOR\r\n",
							"\r\n",
							"# # Eliminar las columnas que no se desean\r\n",
							"# sdf = sdf.drop(\"fechaActualizacion\", \"pipelineID\")\r\n",
							"\r\n",
							"# # Check if the Delta Table exists\r\n",
							"# if DeltaTable.isDeltaTable(spark, delta_table_path):\r\n",
							"#     # Read the existing Delta Table\r\n",
							"#     delta_table = DeltaTable.forPath(spark, delta_table_path)\r\n",
							"\r\n",
							"#     # Get the schema of the existing Delta table\r\n",
							"#     existing_columns = delta_table.toDF().columns\r\n",
							"    \r\n",
							"#     # Añadir columna fechaDelta al DataFrame\r\n",
							"#     sdf = sdf.withColumn(\"fechaDelta\", lit(fecha_delta))\r\n",
							"\r\n",
							"#     # Crear el conjunto de actualizaciones excluyendo 'fechaCarga'\r\n",
							"#     update_set = {f\"existing.{col}\": f\"updates.{col}\" for col in existing_columns if col != 'fechaCarga'}\r\n",
							"\r\n",
							"#     # Merge new data into existing table\r\n",
							"#     delta_table.alias(\"existing\").merge(\r\n",
							"#         source=sdf.alias(\"updates\"),\r\n",
							"#         condition=\" AND \".join(conditions_list)\r\n",
							"#     ).whenMatchedUpdate(\r\n",
							"#         condition=\" OR \".join([f\"existing.{col} != updates.{col}\" for col in existing_columns if col not in ('fechaCarga', 'fechaDelta')]),\r\n",
							"#         set={\r\n",
							"#             \"fechaCarga\": \"updates.fechaCarga\",  # Usar fechaCarga del DataFrame\r\n",
							"#             \"fechaDelta\": \"updates.fechaDelta\",  # Usar fechaDelta del DataFrame\r\n",
							"#             **{f\"existing.{col}\": f\"updates.{col}\" for col in existing_columns if col not in ('fechaCarga', 'fechaDelta')}  # Incluir otros campos\r\n",
							"#         }\r\n",
							"#     ).whenNotMatchedInsert(\r\n",
							"#         values={\r\n",
							"#             \"fechaCarga\": \"updates.fechaCarga\",  # Usar fechaCarga del DataFrame\r\n",
							"#             \"fechaDelta\": fecha_delta,  # Establecer fechaDelta al insertar\r\n",
							"#             **{f\"{col}\": f\"updates.{col}\" for col in existing_columns if col not in ('fechaCarga', 'fechaDelta')}  # Incluir otros campos\r\n",
							"#         }\r\n",
							"#     ).execute()\r\n",
							"# else:\r\n",
							"#     # Crear nueva tabla Delta con nuevos datos, incluyendo la columna fechaDelta\r\n",
							"#     sdf = sdf.withColumn(\"fechaCarga\", sdf.fechaCarga)  # Mantener fechaCarga del DataFrame\r\n",
							"#     sdf = sdf.withColumn(\"fechaDelta\", lit(fecha_delta))  # Establecer fechaDelta al crear la tabla\r\n",
							"#     sdf.write.format('delta').save(delta_table_path)\r\n",
							"\r\n",
							"# spark.sql(f'CREATE TABLE IF NOT EXISTS default.{table_name} USING DELTA LOCATION \\'{delta_table_path}\\'')"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"**Actualizar CSV Configuracion**"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# cuenta =  'datalake1pgc'\r\n",
							"# contendor = 'mdw'\r\n",
							"# archivo = '/bronze/Configuration/ConfiguracionOrigenes.csv'\r\n",
							"\r\n",
							"# #ruta = 'abfss://%s@%s.dfs.core.windows.net/%s' % (contendor, cuenta, archivo)\r\n",
							"# ruta = f'abfss://{contendor}@{cuenta}.dfs.core.windows.net/{archivo}'\r\n",
							"# # Leer CSV\r\n",
							"# #print(ruta)\r\n",
							"# df = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").csv(ruta)\r\n",
							"# #Generamos fecha en formato 'yyyyMMdd'\r\n",
							"# fecha_actual = date_format(current_date(), 'yyyy-MM-dd')\r\n",
							"# fecha_actual = '2022-01-17'\r\n",
							"# # Modificar CSV\r\n",
							"# df_modificado = df.withColumn(\r\n",
							"#     \"UpdateDate\",\r\n",
							"#     when(df[\"Filename\"] == table_name, fecha_actual).otherwise(df[\"UpdateDate\"])\r\n",
							"# )\r\n",
							"# # Sobreescrir CSV\r\n",
							"# #df_modificado.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(ruta)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#df_modificado.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(ruta)\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sparkTFM')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 10
				},
				"autoScale": {
					"enabled": false,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 3,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.4",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "francecentral"
		}
	]
}