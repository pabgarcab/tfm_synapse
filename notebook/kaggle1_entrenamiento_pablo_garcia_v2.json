{
	"name": "kaggle1_entrenamiento_pablo_garcia_v2",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "7216d10a-0a29-4e49-8c58-ab6e30e90df8"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"source": [
					"# Primera entrega Kaggle\n",
					"\n",
					"**Pablo García Caballero**"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"Importamos librerias"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"import numpy as np\n",
					"import pickle\n",
					"import re\n",
					"\n",
					"# Transformación de datos\n",
					"from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder #, TargetEncoder\n",
					"#import category_encoders as ce\n",
					"from category_encoders import TargetEncoder\n",
					"\n",
					"from sklearn.impute import SimpleImputer\n",
					"from sklearn.compose import ColumnTransformer\n",
					"from sklearn.preprocessing import OneHotEncoder\n",
					"\n",
					"# Modelos\n",
					"from sklearn.tree import DecisionTreeClassifier\n",
					"import lightgbm as lgb\n",
					"\n",
					"# Seleccion de variables y tuning de hiperparámetros\n",
					"from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
					"\n",
					"# Métricas para evaluar un modelo de clasificación\n",
					"from sklearn.metrics import classification_report, accuracy_score, precision_recall_curve, auc, roc_curve, roc_auc_score, average_precision_score, confusion_matrix\n",
					"\n",
					"# Librerías para visualización de resultados\n",
					"import matplotlib.pyplot as plt\n",
					"import seaborn as sns\n",
					"\n",
					"pd.set_option('display.max_columns', None)\n",
					"pd.set_option('display.max_rows', None)"
				],
				"execution_count": 55
			},
			{
				"cell_type": "markdown",
				"source": [
					"Definimos la función disponible en el campus para clasificar las columnas"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"def guess_type(column_name:str , df:pd.DataFrame, m=None, original_df=None) -> str:\n",
					"\n",
					"    if df[column_name].dtype == 'O':\n",
					"        return 'text'\n",
					"    try:\n",
					"        if m is not None and bool(m.get_all(name=column_name)):\n",
					"            return m.get_all(name=column_name).type[0]\n",
					"        elif m is not None and bool(m.get_all(name=column_name[:-2])) and original_df is not None:\n",
					"            #lets check if this is a date:\n",
					"            original_colname = column_name[:-2]\n",
					"            atype = original_df[original_colname].dtype\n",
					"            typ = str(atype)\n",
					"            if re.search(\"^date.\", typ):\n",
					"                return 'categorical'\n",
					"            if atype == 'O':\n",
					"                row_sample = original_df[original_colname].iloc[0]\n",
					"                if is_date(row_sample):\n",
					"                    return 'categorical'\n",
					"\n",
					"        #if isinstance(row_sample, float):\n",
					"        #    return 'numerical'\n",
					"        if df[column_name].dtype in ['float64', 'float32', 'float16']:\n",
					"            # we have to check if column was wrong catalogued as numerical\n",
					"            grouped = df[column_name].unique()\n",
					"            if len(grouped) < 10:\n",
					"                #check there are no decimals\n",
					"                for v in grouped:\n",
					"                    are_decimals = v - int(v)\n",
					"                    if are_decimals > 0.0:\n",
					"                        return 'numerical'\n",
					"                return 'categorical'\n",
					"            return 'numerical'\n",
					"\n",
					"        elif df[column_name].dtype in ['int64', 'int32', 'int16', 'int8']:\n",
					"            max = df[column_name].max()\n",
					"            min = df[column_name].min()\n",
					"            diff = max - min\n",
					"            diff2 = int(max) - int(min)\n",
					"            if diff == diff2:\n",
					"                if diff < 10:\n",
					"                    grouped = df[column_name].unique()\n",
					"                    if len(grouped)< 10:\n",
					"                        return 'categorical'\n",
					"            return \"numerical\"\n",
					"        else:\n",
					"            return \"categorical\"\n",
					"    except Exception as e:\n",
					"        return 'categorical'"
				],
				"execution_count": 56
			},
			{
				"cell_type": "markdown",
				"source": [
					"Carga de datos"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"#dfTrain = pd.read_csv(\"MasterBI_Train.csv\", low_memory=False)\n",
					"dfTrain = pd.read_csv(\"D:\\Master BI\\ML\\MasterBI_Train.csv\", low_memory=False)\n",
					"label = \"HasDetections\""
				],
				"execution_count": 108
			},
			{
				"cell_type": "code",
				"source": [
					"dfTrain.head()"
				],
				"execution_count": 94
			},
			{
				"cell_type": "code",
				"source": [
					"dfTrain[[\"Platform\", \"Processor\"]].drop_duplicates().sort_values(by=\"Platform\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"dfTrain[[\"ProductName\", \"EngineVersion\", \"IsBeta\"]].drop_duplicates().sort_values(by=\"EngineVersion\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"Como tienen relación vamos a unifircarlas, y despues a dropearlas"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"dfTrain[\"ProductNameIsBetaEngineVersion\"] = dfTrain[\"ProductName\"] + '_' + dfTrain[\"IsBeta\"].astype(str) + '_' + dfTrain[\"EngineVersion\"]\n",
					"\n",
					"dfTrain[\"PlatformProcessor\"] = dfTrain[\"Platform\"] + '_' + dfTrain[\"Processor\"] \n",
					"\n",
					"# Eliminar las columnas originales \n",
					"dfTrain.drop([\"ProductName\", \"EngineVersion\", \"IsBeta\", \"Platform\", \"Processor\"], axis=1, inplace=True)"
				],
				"execution_count": 110
			},
			{
				"cell_type": "code",
				"source": [
					"dfTrain.head()"
				],
				"execution_count": 107
			},
			{
				"cell_type": "markdown",
				"source": [
					"**EDA**. En primer lugar, realizamos un analisis exploratorio del conjunto de datos. "
				]
			},
			{
				"cell_type": "code",
				"source": [
					"dfTrain.info()"
				],
				"execution_count": 70
			},
			{
				"cell_type": "markdown",
				"source": [
					"Agrupamos las columnas que sean identificadores para posteriormermente elimarlas del df, ya que no son utiles para el entramiento"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"id_colums = [\"MachineIdentifier\"]#, \"ProductName\", \"EngineVersion\", \"AppVersion\", \"AvSigVersion\"]\n",
					"dfTrain.drop(columns=id_colums, inplace=True)"
				],
				"execution_count": 111
			},
			{
				"cell_type": "markdown",
				"source": [
					"Convertimos a categoricas los campos que correspondan en función de la función guess_type"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"for i in dfTrain.columns:\n",
					"    print(f\"{i} = {guess_type(i, dfTrain)}\")\n",
					"    if guess_type(i, dfTrain) == \"categorical\":\n",
					"        dfTrain[i] = dfTrain[i].astype('category')\n",
					"        print(\"convertido\")\n",
					"    else:\n",
					"        print(\"no\")"
				],
				"execution_count": 112
			},
			{
				"cell_type": "code",
				"source": [
					"columnas_cat = dfTrain.select_dtypes(include=[\"object\", \"category\"]).columns.to_list()\n",
					"columnas_num = dfTrain.select_dtypes(include=[\"float64\", \"int64\"]).columns.to_list()"
				],
				"execution_count": 113
			},
			{
				"cell_type": "code",
				"source": [
					"print(columnas_cat)\n",
					"print(columnas_num)"
				],
				"execution_count": 114
			},
			{
				"cell_type": "markdown",
				"source": [
					"Eliminamos el label de nuestro conjunto de categóricas"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"if label in columnas_cat:\n",
					"    columnas_cat.remove(label)\n",
					"    print(\"Label borrado de las cat\")\n",
					"else:\n",
					"    columnas_num.remove(label)\n",
					"    print(\"Label borrado de las num\")"
				],
				"execution_count": 115
			},
			{
				"cell_type": "markdown",
				"source": [
					"Imputamos los nulos mediante la media para las numericas y Imputamos los nulos mediante la moda para las categoricas"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# esto esta mal , primero dividir\n",
					"\n",
					"imp_num = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
					"imp_cat = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
					"#dfTrain[columnas_num] = imp_num.fit_transform(dfTrain[columnas_num])"
				],
				"execution_count": 116
			},
			{
				"cell_type": "markdown",
				"source": [
					"Preparamos la codificación de variables"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"cat_cols = columnas_cat+columnas_num \n",
					"dfTrain = dfTrain[cat_cols+['HasDetections']]"
				],
				"execution_count": 117
			},
			{
				"cell_type": "code",
				"source": [
					"te = TargetEncoder()"
				],
				"execution_count": 78
			},
			{
				"cell_type": "code",
				"source": [
					"preprocessor = ColumnTransformer(\n",
					"                    [('onehot', OneHotEncoder(handle_unknown='ignore'), cat_cols)],\n",
					"                    remainder='passthrough')"
				],
				"execution_count": 118
			},
			{
				"cell_type": "markdown",
				"source": [
					"**Modelo**"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"Dividimos el df en train y test"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"X = dfTrain.drop(label, axis=1)\n",
					"y = dfTrain[label]\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) "
				],
				"execution_count": 119
			},
			{
				"cell_type": "code",
				"source": [
					"X_train[columnas_num] = imp_num.fit_transform(X_train[columnas_num])\n",
					"X_train[columnas_cat] = imp_cat.fit_transform(X_train[columnas_cat])\n",
					"#X_train.isnull().sum()"
				],
				"execution_count": 120
			},
			{
				"cell_type": "code",
				"source": [
					"X_test[columnas_num] = imp_num.transform(X_test[columnas_num])\n",
					"X_test[columnas_cat] = imp_cat.transform(X_test[columnas_cat])\n",
					"#X_test.isnull().sum()"
				],
				"execution_count": 121
			},
			{
				"cell_type": "markdown",
				"source": [
					"Aplicamos el encoder"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"print(columnas_cat)\n",
					"print(columnas_num)"
				],
				"execution_count": 83
			},
			{
				"cell_type": "code",
				"source": [
					"X_train_prep = preprocessor.fit_transform(X_train)\n",
					"X_test_prep  = preprocessor.transform(X_test)"
				],
				"execution_count": 122
			},
			{
				"cell_type": "code",
				"source": [
					"scaler = StandardScaler(with_mean=False)\n",
					"\n",
					"\n",
					"# Ajustar y transformar el conjunto de entrenamiento\n",
					"X_train_prep = scaler.fit_transform(X_train_prep)\n",
					"\n",
					"# Transformar el conjunto de prueba (usando los mismos parámetros de entrenamiento)\n",
					"X_test_prep= scaler.transform(X_test_prep)"
				],
				"execution_count": 123
			},
			{
				"cell_type": "code",
				"source": [
					"# X_train_prep = te.fit_transform(X_train, y_train)\n",
					"# X_test_prep = te.fit_transform(X_test, y_test)\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"Convertimos a df de nuevo"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"Entrenamos el modelo"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"model = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
					"model.fit(X_train_prep, y_train)"
				],
				"execution_count": 57
			},
			{
				"cell_type": "code",
				"source": [
					"import lightgbm as lgb\n",
					"import optuna\n",
					"from lightgbm import LGBMClassifier\n",
					"from sklearn.model_selection import cross_val_score\n",
					"from sklearn.datasets import make_classification\n",
					"from sklearn.model_selection import train_test_split\n",
					"\n",
					"# Generar datos de ejemplo\n",
					"X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
					"\n",
					"# Definir la función objetivo\n",
					"def objective(trial):\n",
					"    # Espacio de búsqueda para los hiperparámetros\n",
					"    param = {\n",
					"        'objective': 'binary',\n",
					"        'metric': 'auc',\n",
					"        'boosting_type': 'gbdt',\n",
					"        'num_leaves': trial.suggest_int('num_leaves', 20, 64),\n",
					"        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
					"        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
					"        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
					"        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
					"        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n",
					"        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
					"        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
					"        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
					"    }\n",
					"\n",
					"    # Crear el modelo LightGBM\n",
					"    clf = LGBMClassifier(**param)\n",
					"\n",
					"    # Validación cruzada para evaluar el modelo\n",
					"    score = cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc').mean()\n",
					"    return score\n",
					"\n",
					"# Crear el estudio con Optuna\n",
					"study = optuna.create_study(direction='maximize')  # Maximizar el AUC\n",
					"study.optimize(objective, n_trials=50)  # Ajusta el número de pruebas (n_trials)\n",
					"\n",
					"# Imprimir los mejores resultados\n",
					"print(\"Mejores hiperparámetros:\", study.best_params)\n",
					"print(\"Mejor puntuación AUC:\", study.best_value)\n",
					"\n",
					"# Entrenar el modelo final con los mejores parámetros\n",
					"best_params = study.best_params\n",
					"final_model = LGBMClassifier(**best_params)\n",
					"final_model.fit(X_train, y_train)\n",
					"\n",
					"# Evaluar el modelo final\n",
					"print(\"Puntuación en el conjunto de prueba:\", final_model.score(X_test, y_test))\n",
					""
				],
				"execution_count": 24
			},
			{
				"cell_type": "code",
				"source": [
					"print(\"Mejores hiperparámetros:\", study.best_params)\n",
					"print(\"Mejor puntuación AUC:\", study.best_value)\n",
					""
				],
				"execution_count": 25
			},
			{
				"cell_type": "code",
				"source": [
					"best_params = study.best_params\n",
					"final_model = LGBMClassifier(**best_params)\n",
					"#final_model.fit(X_train, y_train)"
				],
				"execution_count": 26
			},
			{
				"cell_type": "code",
				"source": [
					"final_model.fit(X_train_prep, y_train)"
				],
				"execution_count": 33
			},
			{
				"cell_type": "code",
				"source": [
					"import lightgbm as lgb\n",
					"clf = lgb.LGBMClassifier()\n",
					"clf.fit(X_train_prep, y_train)\n",
					"\n",
					"# model2 = lightgbm.LGBMClassifier()\n",
					"# model2.fit(X_train_prep, y_train)\n",
					""
				],
				"execution_count": 124
			},
			{
				"cell_type": "markdown",
				"source": [
					"**Predición y evaluación**"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"prediciones = clf.predict(X = X_train_prep, ) # , )\n",
					"pred_proba = clf.predict_proba( X = X_train_prep)\n",
					"\n",
					"data = confusion_matrix(y_train, prediciones)\n",
					"\n",
					"print(\"Matriz de confusión\")\n",
					"plt.figure(figsize=(6,5))\n",
					"sns.set(font_scale=1.4)\n",
					"sns.heatmap(data, cmap=\"Blues\", annot=True, annot_kws={\"size\":12})"
				],
				"execution_count": 125
			},
			{
				"cell_type": "code",
				"source": [
					"prediciones_2 = clf.predict(X = X_test_prep, ) # , )\n",
					"pred_proba_2 = clf.predict_proba( X = X_test_prep)\n",
					"\n",
					"data = confusion_matrix(y_test, prediciones_2)\n",
					"\n",
					"print(\"Matriz de confusión\")\n",
					"plt.figure(figsize=(6,5))\n",
					"sns.set(font_scale=1.4)\n",
					"sns.heatmap(data, cmap=\"Blues\", annot=True, annot_kws={\"size\":12})"
				],
				"execution_count": 126
			},
			{
				"cell_type": "code",
				"source": [
					"print(f\"Acurracy: {round(100*accuracy_score(y_train, prediciones),1)}% \\n\")\n",
					"print(classification_report(y_train, prediciones, digits=3, zero_division=True))"
				],
				"execution_count": 127
			},
			{
				"cell_type": "code",
				"source": [
					"print(f\"Acurracy: {round(100*accuracy_score(y_test, prediciones_2),1)}% \\n\")\n",
					"print(classification_report(y_test, prediciones_2, digits=3, zero_division=True))"
				],
				"execution_count": 128
			},
			{
				"cell_type": "markdown",
				"source": [
					"Curva ROC y AUX"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"fpr, tpr, _ = roc_curve(y_train, pred_proba[:,1])\n",
					"roc_auc = auc(fpr, tpr)\n",
					"\n",
					"plt.figure(figsize = (6,5))\n",
					"lw = 2\n",
					"plt.plot(fpr, tpr, color='darkorange',\n",
					"         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
					"plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
					"plt.xlim([0.0, 1.0])\n",
					"plt.ylim([0.0, 1.05])\n",
					"plt.xlabel('False Positive Rate')\n",
					"plt.ylabel('True Positive Rate')\n",
					"plt.title('Receiver operating characteristic example')\n",
					"plt.legend(loc=\"lower right\")\n",
					"plt.show()"
				],
				"execution_count": 129
			},
			{
				"cell_type": "code",
				"source": [
					"fpr, tpr, _ = roc_curve(y_test, pred_proba_2[:,1])\n",
					"roc_auc = auc(fpr, tpr)\n",
					"\n",
					"plt.figure(figsize = (6,5))\n",
					"lw = 2\n",
					"plt.plot(fpr, tpr, color='darkorange',\n",
					"         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
					"plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
					"plt.xlim([0.0, 1.0])\n",
					"plt.ylim([0.0, 1.05])\n",
					"plt.xlabel('False Positive Rate')\n",
					"plt.ylabel('True Positive Rate')\n",
					"plt.title('Receiver operating characteristic example')\n",
					"plt.legend(loc=\"lower right\")\n",
					"plt.show()"
				],
				"execution_count": 130
			},
			{
				"cell_type": "markdown",
				"source": [
					"**Pase a producción**"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"Replicamos los pasos anteriores, pero sin dividir el df en test/train"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"dfTrainFull = pd.read_csv(\"MasterBI_Train.csv\", low_memory=False)\n",
					"label = \"HasDetections\""
				],
				"execution_count": 97
			},
			{
				"cell_type": "code",
				"source": [
					"id_colums = [\"MachineIdentifier\"]#, \"ProductName\", \"EngineVersion\", \"AppVersion\", \"AvSigVersion\"]\n",
					"dfTrainFull.drop(columns=id_colums, inplace=True)"
				],
				"execution_count": 98
			},
			{
				"cell_type": "code",
				"source": [
					"for i in dfTrainFull.columns:\n",
					"    print(f\"{i} = {guess_type(i, dfTrainFull)}\")\n",
					"    if guess_type(i, dfTrainFull) == \"categorical\":\n",
					"        dfTrainFull[i] = dfTrainFull[i].astype('category')\n",
					"        print(\"convertido\")\n",
					"    else:\n",
					"        print(\"no\")"
				],
				"execution_count": 99
			},
			{
				"cell_type": "code",
				"source": [
					"columnas_cat = dfTrainFull.select_dtypes(include=[\"object\", \"category\"]).columns.to_list()\n",
					"columnas_num = dfTrainFull.select_dtypes(include=[\"float64\", \"int64\"]).columns.to_list()"
				],
				"execution_count": 100
			},
			{
				"cell_type": "code",
				"source": [
					"columnas_cat.remove(label)"
				],
				"execution_count": 101
			},
			{
				"cell_type": "code",
				"source": [
					"imp_num = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
					"dfTrainFull[columnas_num] = imp_num.fit_transform(dfTrainFull[columnas_num])"
				],
				"execution_count": 102
			},
			{
				"cell_type": "code",
				"source": [
					"imp_cat = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
					"dfTrainFull[columnas_cat] = imp_cat.fit_transform(dfTrainFull[columnas_cat])"
				],
				"execution_count": 103
			},
			{
				"cell_type": "code",
				"source": [
					"cat_num = columnas_cat+columnas_num \n",
					"dfTrainFull = dfTrainFull[cat_num+['HasDetections']]"
				],
				"execution_count": 104
			},
			{
				"cell_type": "code",
				"source": [
					"te = TargetEncoder()"
				],
				"execution_count": 105
			},
			{
				"cell_type": "code",
				"source": [
					"X = dfTrainFull.drop(label, axis=1)\n",
					"y = dfTrainFull[label]"
				],
				"execution_count": 106
			},
			{
				"cell_type": "code",
				"source": [
					"X_train_prep = te.fit_transform(X, y)"
				],
				"execution_count": 107
			},
			{
				"cell_type": "code",
				"source": [
					"columnas = dfTrain.columns.to_list()\n",
					"columnas.remove(label)"
				],
				"execution_count": 108
			},
			{
				"cell_type": "code",
				"source": [
					"dfX_train_prep = pd.DataFrame(X_train_prep , columns=columnas)"
				],
				"execution_count": 110
			},
			{
				"cell_type": "code",
				"source": [
					"model = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
					"model.fit(dfX_train_prep, y)"
				],
				"execution_count": 111
			},
			{
				"cell_type": "markdown",
				"source": [
					"Por último, utilizando las funcionalidades de la librería pickle, guardamos todo aquello ques nos va a hacer falta para la inferencia con los datos de test"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Modelo\n",
					"with open(\"output/modelo.pkl\", \"wb\") as c:\n",
					"    pickle.dump(model, c)\n",
					"\n",
					"# Transformación\n",
					"with open(\"output/num_imputer.pkl\", \"wb\") as c:\n",
					"    pickle.dump(imp_num, c)\n",
					"with open(\"output/cat_imputer.pkl\", \"wb\") as c:\n",
					"    pickle.dump(imp_cat, c)\n",
					"with open(\"output/encoder.pkl\", \"wb\") as c:\n",
					"    pickle.dump(te, c)\n",
					"\n",
					"# Lista de todas columnas\n",
					"todas_columnas = dfTrainFull.columns.to_list()\n",
					"with open(\"output/columns.pkl\", \"wb\") as c:\n",
					"    pickle.dump(todas_columnas, c)\n",
					"\n",
					"# Columnas Cat\n",
					"with open(\"output/cat_columns.pkl\", \"wb\") as c:\n",
					"     pickle.dump(columnas_cat, c)\n",
					"\n",
					"# Columnas Num\n",
					"with open(\"output/num_columns.pkl\", \"wb\") as c:\n",
					"     pickle.dump(columnas_num, c)"
				],
				"execution_count": null
			}
		]
	}
}