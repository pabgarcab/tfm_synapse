{
	"name": "_ML",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "0a0c3e7c-fde1-4f58-bb31-f15f973a142c"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"from sklearn.model_selection import train_test_split\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.metrics import mean_squared_error, r2_score\n",
					"import pyodbc\n",
					"\n",
					"import pandas as pd\n",
					"from sklearn.model_selection import train_test_split, KFold\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
					"import pyodbc\n",
					"\n",
					"# Ridge() o Lasso() sklearn.linear_model\n",
					"# DecisionTreeRegressor() sklearn.tree\n",
					"# RandomForestRegressor() de sklearn.ensemble\n",
					"# SVR() sklearn.svm\n",
					"# MLPRegressor() sklearn.neural_network\n",
					"from sklearn.linear_model import Ridge, Lasso\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.feature_selection import RFE\n",
					"from sklearn.feature_selection import SelectFromModel\n",
					"from sklearn.linear_model import LogisticRegression\n",
					"\n",
					"from sklearn.feature_selection import VarianceThreshold\n",
					"from sklearn import preprocessing\n",
					"\n",
					"\n",
					"from sklearn.feature_selection import VarianceThreshold\n",
					"from sklearn.feature_selection import SelectKBest\n",
					"from sklearn.feature_selection import chi2\n",
					"# chi2_selector = SelectKBest(chi2, k=2)\n",
					"# X_kbest = chi2_selector.fit_transform(X, y)\n",
					"from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
					"from sklearn.metrics import roc_auc_score \n",
					"from mlxtend.feature_selection import SequentialFeatureSelector \n",
					"# feature_selector = SequentialFeatureSelector(RandomForestClassifier(n_jobs=-1),\n",
					"#                           k_features=15, forward=False, \n",
					"#                           verbose=2, scoring=’roc_auc’, cv=4)"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"source": [
					"# Query Clima\n",
					"connection = pyodbc.connect('DRIVER={SQL Server};SERVER=DESKTOP-6UKL08J;DATABASE=IncidenceDWH;Trusted_Connection=yes;')\n",
					"\n",
					"# Consulta para obtener los datos climáticos y de incidencia de enfermedad\n",
					"query = \"\"\"\n",
					"SELECT --[Country],\n",
					"      --t.[Year],\n",
					"      [Weathercode]\n",
					"      ,[temperature_2m_max]\n",
					"      ,[temperature_2m_min]\n",
					"      ,[temperature_2m_mean]\n",
					"      ,[apparent_temperature_max]\n",
					"      ,[apparent_temperature_min]\n",
					"      ,[apparent_temperature_mean]\n",
					"      ,[precipitation_sum_mm]\n",
					"      ,[rain_sum_mm]\n",
					"      ,[snowfall_sum_cm]\n",
					"      ,[precipitation_hours_h]\n",
					"      ,[windspeed_10m_max_km/h]\n",
					"      ,[windgusts_10m_max_km/h]\n",
					"      ,[winddirection_10m_dominant]\n",
					"      ,[shortwave_radiation_sum]\n",
					"\t  , Value as Incidencia\n",
					"  FROM [IncidenceDWH].[dbo].[VectorTiempo] AS T\n",
					"  INNER JOIN [dbo].[factIncidences] AS I ON I.Location = T.Country AND I.Year = T.Year \n",
					"  where i.ID_Cause = 569 and ID_Sex = 1\"\"\""
				],
				"execution_count": 41
			},
			{
				"cell_type": "code",
				"source": [
					"# Query Quimicos \n",
					"connection = pyodbc.connect('DRIVER={SQL Server};SERVER=DESKTOP-6UKL08J;DATABASE=IncidenceDWH;Trusted_Connection=yes;')\n",
					"\n",
					"# Consulta para obtener los datos climáticos y de incidencia de enfermedad\n",
					"query = \"\"\"\n",
					"/****** Script para el comando SelectTopNRows de SSMS  ******/\n",
					"SELECT --[Name]\n",
					"      --[Year]\n",
					"      [BC],[CO],[CH4] ,[N20],[Buildings],[CO2],[bio_HCB] ,[fossil_HCB],[NH3],[NMVOC]\n",
					"      ,[NOx],[OC],[bio_PAH_BaP],[fossil_PAH_BaP]\n",
					"      ,[PAH_BbF],[bio_PAH_IcdP],[fossil_PAH_IcdP],[bio_PAH_BkF],[fossil_PAH_BbF],[bio_PCB],[fossil_PCB],[bio_PCDD_F],[fossil_PCDD_F],[PM10],[PM25],[SO2]\n",
					"\t  , Value as Incidencia\n",
					"  FROM [IncidenceDWH].[dbo].[vectorQuimicosFloat] AS T\n",
					"  INNER JOIN [dbo].[factIncidences] AS I ON I.Location = T.[Name] AND I.Year = T.Year \n",
					"  where i.ID_Cause = 559 and ID_Sex = 1\n",
					"  AND   [BC] IS NOT NULL AND [CO] IS NOT NULL AND  [CH4] IS NOT NULL\n",
					"   AND   [N20] IS NOT NULL  AND   [Buildings]  IS NOT NULL AND   [CO2] IS NOT NULL\n",
					"   AND   [bio_HCB] IS NOT NULL AND   [fossil_HCB] IS NOT NULL\n",
					"   AND   [NH3] IS NOT NULL AND   [NMVOC] IS NOT NULL\n",
					"     AND [NOx] IS NOT NULL AND [OC] IS NOT NULL AND [bio_PAH_BaP] IS NOT NULL AND [fossil_PAH_BaP] IS NOT NULL AND [PAH_BbF] IS NOT NULL AND [bio_PAH_IcdP] IS NOT NULL AND [fossil_PAH_IcdP] IS NOT NULL AND [bio_PAH_BkF] IS NOT NULL AND [fossil_PAH_BbF] IS NOT NULL AND [bio_PCB] IS NOT NULL AND [fossil_PCB] IS NOT NULL AND [bio_PCDD_F] IS NOT NULL AND [fossil_PCDD_F] IS NOT NULL AND[PM10] IS NOT NULL AND [PM25] IS NOT NULL AND [SO2] IS NOT NULL\"\"\""
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"# S x Q\n",
					"\n",
					"connection = pyodbc.connect('DRIVER={SQL Server};SERVER=DESKTOP-6UKL08J;DATABASE=IncidenceDWH;Trusted_Connection=yes;')\n",
					"\n",
					"query = \"\"\"\n",
					"-- Socio x Quimicos\n",
					"SELECT --[Name]\n",
					"      --[Year]\n",
					"      [BC]\n",
					"      ,[CO]\n",
					"      ,[CH4]\n",
					"      ,[N20]\n",
					"      ,[Buildings]\n",
					"      ,[CO2]\n",
					"      ,[bio_HCB]\n",
					"      ,[fossil_HCB]\n",
					"      ,[NH3]\n",
					"      ,[NMVOC]\n",
					"      ,[NOx]\n",
					"      ,[OC]\n",
					"      ,[bio_PAH_BaP]\n",
					"      ,[fossil_PAH_BaP]\n",
					"      ,[PAH_BbF]\n",
					"      ,[bio_PAH_IcdP]\n",
					"      ,[fossil_PAH_IcdP]\n",
					"      ,[bio_PAH_BkF]\n",
					"      ,[fossil_PAH_BbF]\n",
					"      ,[bio_PCB]\n",
					"      ,[fossil_PCB]\n",
					"      ,[bio_PCDD_F]\n",
					"      ,[fossil_PCDD_F]\n",
					"      ,[PM10]\n",
					"      ,[PM25]\n",
					"      ,[SO2]\n",
					"\t        [GDP]\n",
					"      ,[GDP_per_capita]\n",
					"      ,[GDP_per_capita_growth]\n",
					"      ,[Gross_value_added]\n",
					"      ,[Life_expectancy_birth(years)]\n",
					"      ,[Access_electricity(%)]\n",
					"      ,[Agricultural_land]\n",
					"      ,[Services]\n",
					"      ,[Unemployment]\n",
					"      ,[Control_Corruption]\n",
					"      ,[Contributing_family]\n",
					"      ,[Government Effectiveness]\n",
					"      ,[Political_Stability]\n",
					"      ,[LAW]\n",
					"      ,[Regulatory_Quality]\n",
					"\t  , Value as Incidencia\n",
					"  FROM [IncidenceDWH].[dbo].[vectorQuimicosFloat] AS T\n",
					"  INNER JOIN [dbo].[factIncidences] AS I ON I.Location = T.[Name] AND I.Year = T.Year \n",
					"  INNER JOIN dbo.vectorSocio2 AS t1  ON I.Location = T1.Country AND I.Year = T1.Year \n",
					"  where i.ID_Cause = 574 and ID_Sex = 2\n",
					"\n",
					"  AND   [BC] IS NOT NULL\n",
					"   AND   [CO] IS NOT NULL\n",
					"   AND  [CH4] IS NOT NULL\n",
					"   AND   [N20] IS NOT NULL\n",
					"   AND   [Buildings]  IS NOT NULL\n",
					"   AND   [CO2] IS NOT NULL\n",
					"   AND   [bio_HCB] IS NOT NULL \n",
					"   AND   [fossil_HCB] IS NOT NULL\n",
					"   AND   [NH3] IS NOT NULL\n",
					"   AND   [NMVOC] IS NOT NULL\n",
					"     AND [NOx] IS NOT NULL\n",
					"      AND [OC] IS NOT NULL\n",
					"      AND [bio_PAH_BaP] IS NOT NULL\n",
					"      AND [fossil_PAH_BaP] IS NOT NULL\n",
					"      AND [PAH_BbF] IS NOT NULL\n",
					"      AND [bio_PAH_IcdP] IS NOT NULL\n",
					"      AND [fossil_PAH_IcdP] IS NOT NULL\n",
					"      AND [bio_PAH_BkF] IS NOT NULL\n",
					"      AND [fossil_PAH_BbF] IS NOT NULL\n",
					"      AND [bio_PCB] IS NOT NULL\n",
					"      AND [fossil_PCB] IS NOT NULL\n",
					"      AND [bio_PCDD_F] IS NOT NULL\n",
					"      AND [fossil_PCDD_F] IS NOT NULL\n",
					"      AND[PM10] IS NOT NULL\n",
					"      AND [PM25] IS NOT NULL\n",
					"      AND [SO2] IS NOT NULL\n",
					"\t  AND\n",
					"  [GDP] IS NOT NULL\n",
					"      AND [GDP_per_capita] IS NOT NULL\n",
					"      AND [GDP_per_capita_growth] IS NOT NULL\n",
					"      AND [Gross_value_added] IS NOT NULL\n",
					"      AND [Life_expectancy_birth(years)] IS NOT NULL\n",
					"      AND [Access_electricity(%)] IS NOT NULL\n",
					"     -- AND [Broad_money] IS NOT NULL\n",
					"      AND [Agricultural_land] IS NOT NULL\n",
					"\n",
					"      --AND [Tax_revenue] IS NOT NULL\n",
					"      \n",
					"\t  AND [Services] IS NOT NULL\n",
					"\n",
					"\t        AND[Unemployment] IS NOT NULL\n",
					"      AND[Control_Corruption] IS NOT NULL\n",
					"      AND[Contributing_family] IS NOT NULL\n",
					"      AND[Government Effectiveness] IS NOT NULL\n",
					"      AND[Political_Stability] IS NOT NULL\n",
					"      AND[LAW] IS NOT NULL\n",
					"      AND[Regulatory_Quality] IS NOT NULL\"\"\""
				],
				"execution_count": 39
			},
			{
				"cell_type": "code",
				"source": [
					"# Query Clima X Quimicos\n",
					"connection = pyodbc.connect('DRIVER={SQL Server};SERVER=DESKTOP-6UKL08J;DATABASE=IncidenceDWH;Trusted_Connection=yes;')\n",
					"\n",
					"query = \"\"\"\n",
					"SELECT --[Name]\n",
					"      --[Year]\n",
					"      [BC]\n",
					"      ,[CO]\n",
					"      ,[CH4]\n",
					"      ,[N20]\n",
					"      ,[Buildings]\n",
					"      ,[CO2]\n",
					"      ,[bio_HCB]\n",
					"      ,[fossil_HCB]\n",
					"      ,[NH3]\n",
					"      ,[NMVOC]\n",
					"      ,[NOx]\n",
					"      ,[OC]\n",
					"      ,[bio_PAH_BaP]\n",
					"      ,[fossil_PAH_BaP]\n",
					"      ,[PAH_BbF]\n",
					"      ,[bio_PAH_IcdP]\n",
					"      ,[fossil_PAH_IcdP]\n",
					"      ,[bio_PAH_BkF]\n",
					"      ,[fossil_PAH_BbF]\n",
					"      ,[bio_PCB]\n",
					"      ,[fossil_PCB]\n",
					"      ,[bio_PCDD_F]\n",
					"      ,[fossil_PCDD_F]\n",
					"      ,[PM10]\n",
					"      ,[PM25]\n",
					"      ,[SO2]\n",
					"\t        ,[Weathercode]\n",
					"      ,[temperature_2m_max]\n",
					"      ,[temperature_2m_min]\n",
					"      ,[temperature_2m_mean]\n",
					"      ,[apparent_temperature_max]\n",
					"      ,[apparent_temperature_min]\n",
					"      ,[apparent_temperature_mean]\n",
					"      ,[precipitation_sum_mm]\n",
					"      ,[rain_sum_mm]\n",
					"      ,[snowfall_sum_cm]\n",
					"      ,[precipitation_hours_h]\n",
					"      ,[windspeed_10m_max_km/h]\n",
					"      ,[windgusts_10m_max_km/h]\n",
					"      ,[winddirection_10m_dominant]\n",
					"      ,[shortwave_radiation_sum]\n",
					"\t  , Value as Incidencia\n",
					"  FROM [IncidenceDWH].[dbo].[vectorQuimicosFloat] AS T\n",
					"  INNER JOIN [dbo].[factIncidences] AS I ON I.Location = T.[Name] AND I.Year = T.Year \n",
					"  INNER JOIN dbo.VectorTiempo AS t1  ON I.Location = T1.Country AND I.Year = T1.Year \n",
					"  where i.ID_Cause = 571 and ID_Sex = 2\n",
					"\n",
					"  AND   [BC] IS NOT NULL\n",
					"   AND   [CO] IS NOT NULL\n",
					"   AND  [CH4] IS NOT NULL\n",
					"   AND   [N20] IS NOT NULL\n",
					"   AND   [Buildings]  IS NOT NULL\n",
					"   AND   [CO2] IS NOT NULL\n",
					"   AND   [bio_HCB] IS NOT NULL\n",
					"   AND   [fossil_HCB] IS NOT NULL\n",
					"   AND   [NH3] IS NOT NULL\n",
					"   AND   [NMVOC] IS NOT NULL\n",
					"     AND [NOx] IS NOT NULL\n",
					"      AND [OC] IS NOT NULL\n",
					"      AND [bio_PAH_BaP] IS NOT NULL\n",
					"      AND [fossil_PAH_BaP] IS NOT NULL\n",
					"      AND [PAH_BbF] IS NOT NULL\n",
					"      AND [bio_PAH_IcdP] IS NOT NULL\n",
					"      AND [fossil_PAH_IcdP] IS NOT NULL\n",
					"      AND [bio_PAH_BkF] IS NOT NULL\n",
					"      AND [fossil_PAH_BbF] IS NOT NULL\n",
					"      AND [bio_PCB] IS NOT NULL\n",
					"      AND [fossil_PCB] IS NOT NULL\n",
					"      AND [bio_PCDD_F] IS NOT NULL\n",
					"      AND [fossil_PCDD_F] IS NOT NULL\n",
					"      AND[PM10] IS NOT NULL\n",
					"      AND [PM25] IS NOT NULL\n",
					"      AND [SO2] IS NOT NULL\"\"\""
				],
				"execution_count": 26
			},
			{
				"cell_type": "code",
				"source": [
					"connection = pyodbc.connect('DRIVER={SQL Server};SERVER=DESKTOP-6UKL08J;DATABASE=IncidenceDWH;Trusted_Connection=yes;')\n",
					"\n",
					"# Consulta para obtener los datos climáticos y de incidencia de enfermedad\n",
					"query = \"\"\" \n",
					"SELECT --[Country],\n",
					"      --t.[Year],\n",
					"      [Weathercode]\n",
					"      ,[temperature_2m_max]\n",
					"      ,[temperature_2m_min]\n",
					"      ,[temperature_2m_mean]\n",
					"      ,[apparent_temperature_max]\n",
					"      ,[apparent_temperature_min]\n",
					"      ,[apparent_temperature_mean]\n",
					"      ,[precipitation_sum_mm]\n",
					"      ,[rain_sum_mm]\n",
					"      ,[snowfall_sum_cm]\n",
					"      ,[precipitation_hours_h]\n",
					"      ,[windspeed_10m_max_km/h]\n",
					"      ,[windgusts_10m_max_km/h]\n",
					"      ,[winddirection_10m_dominant]\n",
					"      ,[shortwave_radiation_sum]\n",
					"\t  , Value as incidencia\n",
					"\t  , GDP\n",
					"\t  ,GDP_per_capita\n",
					"\t  ,CO2_emissions\n",
					"  FROM [IncidenceDWH].[dbo].[VectorTiempo] AS T\n",
					"  INNER JOIN [dbo].[factIncidences] AS I ON I.Location = T.Country AND I.Year = T.Year \n",
					"  INNER JOIN vectorPib AS P ON P.Location = T.Country AND P.Year = T.Year \n",
					"  where i.ID_Cause = 568 and ID_Sex = 1\n",
					"  AND GDP NOT LIKE '..' AND GDP_per_capita NOT LIKE '..'  AND CO2_emissions NOT LIKE '..' \"\"\""
				],
				"execution_count": 66
			},
			{
				"cell_type": "code",
				"source": [
					"# Todo junto\n",
					"connection = pyodbc.connect('DRIVER={SQL Server};SERVER=DESKTOP-6UKL08J;DATABASE=IncidenceDWH;Trusted_Connection=yes;')\n",
					"query = \"\"\"SELECT --[Name]\n",
					"      --[Year]\n",
					"      [BC]\n",
					"      ,[CO]\n",
					"      ,[CH4]\n",
					"      ,[N20]\n",
					"      ,[Buildings]\n",
					"      ,[CO2]\n",
					"      ,[bio_HCB]\n",
					"      ,[fossil_HCB]\n",
					"      ,[NH3]\n",
					"      ,[NMVOC]\n",
					"      ,[NOx]\n",
					"      ,[OC]\n",
					"      ,[bio_PAH_BaP]\n",
					"      ,[fossil_PAH_BaP]\n",
					"      ,[PAH_BbF]\n",
					"      ,[bio_PAH_IcdP]\n",
					"      ,[fossil_PAH_IcdP]\n",
					"      ,[bio_PAH_BkF]\n",
					"      ,[fossil_PAH_BbF]\n",
					"      ,[bio_PCB]\n",
					"      ,[fossil_PCB]\n",
					"      ,[bio_PCDD_F]\n",
					"      ,[fossil_PCDD_F]\n",
					"      ,[PM10]\n",
					"      ,[PM25]\n",
					"      ,[SO2]\n",
					"\t        ,[Weathercode]\n",
					"      ,[temperature_2m_max]\n",
					"      ,[temperature_2m_min]\n",
					"      ,[temperature_2m_mean]\n",
					"      ,[apparent_temperature_max]\n",
					"      ,[apparent_temperature_min]\n",
					"      ,[apparent_temperature_mean]\n",
					"      ,[precipitation_sum_mm]\n",
					"      ,[rain_sum_mm]\n",
					"      ,[snowfall_sum_cm]\n",
					"      ,[precipitation_hours_h]\n",
					"      ,[windspeed_10m_max_km/h]\n",
					"      ,[windgusts_10m_max_km/h]\n",
					"      ,[winddirection_10m_dominant]\n",
					"      ,[shortwave_radiation_sum]\n",
					"      ,[GDP]\n",
					"      ,[GDP_per_capita]\n",
					"      ,[GDP_per_capita_growth]\n",
					"      ,[Gross_value_added]\n",
					"      ,[Life_expectancy_birth(years)]\n",
					"      ,[Access_electricity(%)]\n",
					"      --,[Broad_money]\n",
					"      ,[Agricultural_land]\n",
					"      --,[Unemployment(%)]\n",
					"      --,[Tax_revenue]\n",
					"      ,[Services]\n",
					"\t        ,[Unemployment]\n",
					"      ,[Control_Corruption]\n",
					"      ,[Contributing_family]\n",
					"      ,[Government Effectiveness]\n",
					"      ,[Political_Stability]\n",
					"      ,[LAW]\n",
					"      ,[Regulatory_Quality]\n",
					"\t  , Value as Incidencia\n",
					"  FROM [IncidenceDWH].[dbo].[vectorQuimicosFloat] AS T\n",
					"  INNER JOIN [dbo].[factIncidences] AS I ON I.Location = T.[Name] AND I.Year = T.Year \n",
					"  INNER JOIN dbo.vectorSocio2 AS t2 ON I.Location = T2.Country AND I.Year = T2.Year \n",
					"  INNER JOIN dbo.VectorTiempo AS t1  ON I.Location = T1.Country AND I.Year = T1.Year \n",
					"  where i.ID_Cause = 559 and ID_Sex = 1\n",
					"\n",
					"  AND   [BC] IS NOT NULL\n",
					"   AND   [CO] IS NOT NULL\n",
					"   AND  [CH4] IS NOT NULL\n",
					"   AND   [N20] IS NOT NULL\n",
					"   AND   [Buildings]  IS NOT NULL\n",
					"   AND   [CO2] IS NOT NULL\n",
					"   AND   [bio_HCB] IS NOT NULL\n",
					"   AND   [fossil_HCB] IS NOT NULL\n",
					"   AND   [NH3] IS NOT NULL\n",
					"   AND   [NMVOC] IS NOT NULL\n",
					"     AND [NOx] IS NOT NULL\n",
					"      AND [OC] IS NOT NULL\n",
					"      AND [bio_PAH_BaP] IS NOT NULL\n",
					"      AND [fossil_PAH_BaP] IS NOT NULL\n",
					"      AND [PAH_BbF] IS NOT NULL\n",
					"      AND [bio_PAH_IcdP] IS NOT NULL\n",
					"      AND [fossil_PAH_IcdP] IS NOT NULL\n",
					"      AND [bio_PAH_BkF] IS NOT NULL\n",
					"      AND [fossil_PAH_BbF] IS NOT NULL\n",
					"      AND [bio_PCB] IS NOT NULL\n",
					"      AND [fossil_PCB] IS NOT NULL\n",
					"      AND [bio_PCDD_F] IS NOT NULL\n",
					"      AND [fossil_PCDD_F] IS NOT NULL\n",
					"      AND[PM10] IS NOT NULL\n",
					"      AND [PM25] IS NOT NULL\n",
					"      AND [SO2] IS NOT NULL\n",
					"\n",
					"\t      AND   [GDP] IS NOT NULL\n",
					"      AND [GDP_per_capita] IS NOT NULL\n",
					"      AND [GDP_per_capita_growth] IS NOT NULL\n",
					"      AND [Gross_value_added] IS NOT NULL\n",
					"      AND [Life_expectancy_birth(years)] IS NOT NULL\n",
					"      AND [Access_electricity(%)] IS NOT NULL\n",
					"     -- AND [Broad_money] IS NOT NULL\n",
					"      AND [Agricultural_land] IS NOT NULL\n",
					"\n",
					"      --AND [Tax_revenue] IS NOT NULL\n",
					"      \n",
					"\t  AND [Services] IS NOT NULL\n",
					"\n",
					"\t        AND[Unemployment] IS NOT NULL\n",
					"      AND[Control_Corruption] IS NOT NULL\n",
					"      AND[Contributing_family] IS NOT NULL\n",
					"      AND[Government Effectiveness] IS NOT NULL\n",
					"      AND[Political_Stability] IS NOT NULL\n",
					"      AND[LAW] IS NOT NULL\n",
					"      AND[Regulatory_Quality] IS NOT NULL \"\"\""
				],
				"execution_count": 50
			},
			{
				"cell_type": "code",
				"source": [
					"# C x Q\n",
					"\n",
					"connection = pyodbc.connect('DRIVER={SQL Server};SERVER=DESKTOP-6UKL08J;DATABASE=IncidenceDWH;Trusted_Connection=yes;')\n",
					"\n",
					"# Consulta para obtener los datos climáticos y de incidencia de enfermedad\n",
					"query = \"\"\" \n",
					"-- Clima x Quimicos\n",
					"\n",
					"SELECT --[Name]\n",
					"      --[Year]\n",
					"      [BC]\n",
					"      ,[CO]\n",
					"      ,[CH4]\n",
					"      ,[N20]\n",
					"      ,[Buildings]\n",
					"      ,[CO2]\n",
					"      ,[bio_HCB]\n",
					"      ,[fossil_HCB]\n",
					"      ,[NH3]\n",
					"      ,[NMVOC]\n",
					"      ,[NOx]\n",
					"      ,[OC]\n",
					"      ,[bio_PAH_BaP]\n",
					"      ,[fossil_PAH_BaP]\n",
					"      ,[PAH_BbF]\n",
					"      ,[bio_PAH_IcdP]\n",
					"      ,[fossil_PAH_IcdP]\n",
					"      ,[bio_PAH_BkF]\n",
					"      ,[fossil_PAH_BbF]\n",
					"      ,[bio_PCB]\n",
					"      ,[fossil_PCB]\n",
					"      ,[bio_PCDD_F]\n",
					"      ,[fossil_PCDD_F]\n",
					"      ,[PM10]\n",
					"      ,[PM25]\n",
					"      ,[SO2]\n",
					"\t        ,[Weathercode]\n",
					"      ,[temperature_2m_max]\n",
					"      ,[temperature_2m_min]\n",
					"      ,[temperature_2m_mean]\n",
					"      ,[apparent_temperature_max]\n",
					"      ,[apparent_temperature_min]\n",
					"      ,[apparent_temperature_mean]\n",
					"      ,[precipitation_sum_mm]\n",
					"      ,[rain_sum_mm]\n",
					"      ,[snowfall_sum_cm]\n",
					"      ,[precipitation_hours_h]\n",
					"      ,[windspeed_10m_max_km/h]\n",
					"      ,[windgusts_10m_max_km/h]\n",
					"      ,[winddirection_10m_dominant]\n",
					"      ,[shortwave_radiation_sum]\n",
					"\t  , Value as Incidencia\n",
					"  FROM [IncidenceDWH].[dbo].[vectorQuimicosFloat] AS T\n",
					"  INNER JOIN [dbo].[factIncidences] AS I ON I.Location = T.[Name] AND I.Year = T.Year \n",
					"  INNER JOIN dbo.VectorTiempo AS t1  ON I.Location = T1.Country AND I.Year = T1.Year \n",
					"  where i.ID_Cause = 570 and ID_Sex = 1\n",
					"\n",
					"  AND   [BC] IS NOT NULL\n",
					"   AND   [CO] IS NOT NULL\n",
					"   AND  [CH4] IS NOT NULL\n",
					"   AND   [N20] IS NOT NULL\n",
					"   AND   [Buildings]  IS NOT NULL\n",
					"   AND   [CO2] IS NOT NULL\n",
					"   AND   [bio_HCB] IS NOT NULL\n",
					"   AND   [fossil_HCB] IS NOT NULL\n",
					"   AND   [NH3] IS NOT NULL\n",
					"   AND   [NMVOC] IS NOT NULL\n",
					"     AND [NOx] IS NOT NULL\n",
					"      AND [OC] IS NOT NULL\n",
					"      AND [bio_PAH_BaP] IS NOT NULL\n",
					"      AND [fossil_PAH_BaP] IS NOT NULL\n",
					"      AND [PAH_BbF] IS NOT NULL\n",
					"      AND [bio_PAH_IcdP] IS NOT NULL\n",
					"      AND [fossil_PAH_IcdP] IS NOT NULL\n",
					"      AND [bio_PAH_BkF] IS NOT NULL\n",
					"      AND [fossil_PAH_BbF] IS NOT NULL\n",
					"      AND [bio_PCB] IS NOT NULL\n",
					"      AND [fossil_PCB] IS NOT NULL\n",
					"      AND [bio_PCDD_F] IS NOT NULL\n",
					"      AND [fossil_PCDD_F] IS NOT NULL\n",
					"      AND[PM10] IS NOT NULL\n",
					"      AND [PM25] IS NOT NULL\n",
					"      AND [SO2] IS NOT NULL\n",
					"\n",
					"\"\"\"\n",
					""
				],
				"execution_count": 18
			},
			{
				"cell_type": "code",
				"source": [
					"connection = pyodbc.connect('DRIVER={SQL Server};SERVER=DESKTOP-6UKL08J;DATABASE=IncidenceDWH;Trusted_Connection=yes;')\n",
					"\n",
					"# Consulta para obtener los datos climáticos y de incidencia de enfermedad\n",
					"query = \"\"\"\n",
					"SELECT  --[Country]\n",
					"      --,[Year]\n",
					"      [GDP]\n",
					"      ,[GDP_per_capita]\n",
					"      ,[GDP_per_capita_growth]\n",
					"      ,[Gross_value_added]\n",
					"      ,[Life_expectancy_birth(years)]\n",
					"      ,[Access_electricity(%)]\n",
					"      ,[Agricultural_land]\n",
					"      ,[Services]\n",
					"      ,[Unemployment]\n",
					"      ,[Control_Corruption]\n",
					"      ,[Contributing_family]\n",
					"      ,[Government Effectiveness]\n",
					"      ,[Political_Stability]\n",
					"      ,[LAW]\n",
					"      ,[Regulatory_Quality]\n",
					"\t  ,Value AS Incidencia\n",
					"  FROM [IncidenceDWH].[dbo].[vectorSocio2] as T\n",
					"  INNER JOIN [dbo].[factIncidences] AS I ON I.Location = T.Country AND I.Year = T.Year \n",
					"\n",
					"  WHERE   \n",
					"    i.ID_Cause = 579 and ID_Sex = 2 AND\n",
					"  [GDP] IS NOT NULL\n",
					"      AND [GDP_per_capita] IS NOT NULL\n",
					"      AND [GDP_per_capita_growth] IS NOT NULL\n",
					"      AND [Gross_value_added] IS NOT NULL\n",
					"      AND [Life_expectancy_birth(years)] IS NOT NULL\n",
					"      AND [Access_electricity(%)] IS NOT NULL\n",
					"     -- AND [Broad_money] IS NOT NULL\n",
					"      AND [Agricultural_land] IS NOT NULL\n",
					"\n",
					"      --AND [Tax_revenue] IS NOT NULL\n",
					"      \n",
					"\t  AND [Services] IS NOT NULL\n",
					"\n",
					"\t        AND[Unemployment] IS NOT NULL\n",
					"      AND[Control_Corruption] IS NOT NULL\n",
					"      AND[Contributing_family] IS NOT NULL\n",
					"      AND[Government Effectiveness] IS NOT NULL\n",
					"      AND[Political_Stability] IS NOT NULL\n",
					"      AND[LAW] IS NOT NULL\n",
					"      AND[Regulatory_Quality] IS NOT NULL\"\"\""
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"df = pd.read_sql(query, connection)\n",
					"\n",
					"# Calcular la desviación estándar de cada columna\n",
					"std_devs = df.std()\n",
					"\n",
					"# Ordenar las columnas por desviación estándar en orden ascendente\n",
					"sorted_columns = std_devs.sort_values(ascending=True)\n",
					"\n",
					"# Seleccionar las 5 columnas con las desviaciones estándar más bajas\n",
					"top_5_similar_columns = sorted_columns.index[:5]\n",
					"\n",
					"print(f\"Las 5 columnas con los valores más similares son:\")\n",
					"print(top_5_similar_columns)"
				],
				"execution_count": 53
			},
			{
				"cell_type": "code",
				"source": [
					"# 579 1 Junto Original\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					"\n",
					""
				],
				"execution_count": 51
			},
			{
				"cell_type": "code",
				"source": [
					"# 579 2 Junto Varianza\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					"\n",
					""
				],
				"execution_count": 49
			},
			{
				"cell_type": "code",
				"source": [
					"# 575 1 Junto Orginal\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					"\n",
					""
				],
				"execution_count": 47
			},
			{
				"cell_type": "code",
				"source": [
					"# 575 2 Junto Backward\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					"\n",
					""
				],
				"execution_count": 45
			},
			{
				"cell_type": "code",
				"source": [
					"# 574 1 Junto Varianza\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					"\n",
					""
				],
				"execution_count": 43
			},
			{
				"cell_type": "code",
				"source": [
					"# 574 2 SxQ Original \n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					"\n",
					""
				],
				"execution_count": 40
			},
			{
				"cell_type": "code",
				"source": [
					"# 573 1 Junto Original\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					"\n",
					""
				],
				"execution_count": 38
			},
			{
				"cell_type": "code",
				"source": [
					"# 573 2 SxQ Varianza\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					"\n",
					""
				],
				"execution_count": 36
			},
			{
				"cell_type": "code",
				"source": [
					"# 571 1 Junto Varianza\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					"\n",
					""
				],
				"execution_count": 33
			},
			{
				"cell_type": "code",
				"source": [
					"# 571 2 CxQ Backward\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					"\n",
					""
				],
				"execution_count": 31
			},
			{
				"cell_type": "code",
				"source": [
					"# 570 1 CxQ Backward\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					"\n",
					""
				],
				"execution_count": 25
			},
			{
				"cell_type": "code",
				"source": [
					"# 570 2 C xQ Original\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					"\n",
					""
				],
				"execution_count": 23
			},
			{
				"cell_type": "code",
				"source": [
					"# 568 1\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 17
			},
			{
				"cell_type": "code",
				"source": [
					"# 568 2   # Repetir \n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"source": [
					"# 559 1\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"source": [
					"# NO # 559 3\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"source": [
					"from sklearn.ensemble import RandomForestClassifier\n",
					"import pandas as pd\n",
					"\n",
					"# Crear un DataFrame de ejemplo (reemplaza esto con tus datos)\n",
					"data = {\n",
					"    'Feature1': [1, 2, 3, 4, 5],\n",
					"    'Feature2': [2, 3, 4, 5, 6],\n",
					"    'Feature3': [1, 1, 0, 1, 1],\n",
					"    'Target': [0, 1, 0, 1, 0]\n",
					"}\n",
					"\n",
					"df = pd.DataFrame(data)\n",
					"\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Target', axis=1)\n",
					"y = df['Target']\n",
					"\n",
					"# Crear un modelo de Random Forest\n",
					"rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
					"\n",
					"# Entrenar el modelo\n",
					"rf.fit(X, y)\n",
					"\n",
					"# Obtener la importancia de las características\n",
					"feature_importances = rf.feature_importances_\n",
					"\n",
					"# Crear un DataFrame para visualizar las importancias\n",
					"importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
					"\n",
					"# Ordenar las características por importancia en orden descendente\n",
					"importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
					"\n",
					"# Imprimir las características más importantes\n",
					"print(importance_df)\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    #'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    #('Variance Threshold', VarianceThreshold()),\n",
					"    #('Percentile', SelectPercentile()),\n",
					"    #('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"\n",
					"\n",
					"        # Calcular la importancia de características si el modelo es un Random Forest\n",
					"        if isinstance(model, RandomForestRegressor):\n",
					"            feature_importances = model.feature_importances_\n",
					"            feature_names = X_train.columns.tolist()\n",
					"            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
					"            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
					"            print(f'Importancia de características para {model_name}:')\n",
					"            print(feature_importance_df)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"source": [
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# 573 1 climaXsocio\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    #'Linear Regression': LinearRegression(),\n",
					"    #'Decision Tree': DecisionTreeRegressor(),\n",
					"    #'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 98
			},
			{
				"cell_type": "code",
				"source": [
					"# Socio x Quimicos\n",
					"connection = pyodbc.connect('DRIVER={SQL Server};SERVER=DESKTOP-6UKL08J;DATABASE=IncidenceDWH;Trusted_Connection=yes;')\n",
					"\n",
					"query = \"\"\"\n",
					"\n",
					"SELECT --[Name]\n",
					"      --[Year]\n",
					"      [BC]\n",
					"      ,[CO]\n",
					"      ,[CH4]\n",
					"      ,[N20]\n",
					"      ,[Buildings]\n",
					"      ,[CO2]\n",
					"      ,[bio_HCB]\n",
					"      ,[fossil_HCB]\n",
					"      ,[NH3]\n",
					"      ,[NMVOC]\n",
					"      ,[NOx]\n",
					"      ,[OC]\n",
					"      ,[bio_PAH_BaP]\n",
					"      ,[fossil_PAH_BaP]\n",
					"      ,[PAH_BbF]\n",
					"      ,[bio_PAH_IcdP]\n",
					"      ,[fossil_PAH_IcdP]\n",
					"      ,[bio_PAH_BkF]\n",
					"      ,[fossil_PAH_BbF]\n",
					"      ,[bio_PCB]\n",
					"      ,[fossil_PCB]\n",
					"      ,[bio_PCDD_F]\n",
					"      ,[fossil_PCDD_F]\n",
					"      ,[PM10]\n",
					"      ,[PM25]\n",
					"      ,[SO2]\n",
					"\t        [GDP]\n",
					"      ,[GDP_per_capita]\n",
					"      ,[GDP_per_capita_growth]\n",
					"      ,[Gross_value_added]\n",
					"      ,[Life_expectancy_birth(years)]\n",
					"      ,[Access_electricity(%)]\n",
					"      ,[Agricultural_land]\n",
					"      ,[Services]\n",
					"      ,[Unemployment]\n",
					"      ,[Control_Corruption]\n",
					"      ,[Contributing_family]\n",
					"      ,[Government Effectiveness]\n",
					"      ,[Political_Stability]\n",
					"      ,[LAW]\n",
					"      ,[Regulatory_Quality]\n",
					"\t  , Value as Incidencia\n",
					"  FROM [IncidenceDWH].[dbo].[vectorQuimicosFloat] AS T\n",
					"  INNER JOIN [dbo].[factIncidences] AS I ON I.Location = T.[Name] AND I.Year = T.Year \n",
					"  INNER JOIN dbo.vectorSocio2 AS t1  ON I.Location = T1.Country AND I.Year = T1.Year \n",
					"  where i.ID_Cause = 575 and ID_Sex = 1\n",
					"\n",
					"  AND   [BC] IS NOT NULL\n",
					"   AND   [CO] IS NOT NULL\n",
					"   AND  [CH4] IS NOT NULL\n",
					"   AND   [N20] IS NOT NULL\n",
					"   AND   [Buildings]  IS NOT NULL\n",
					"   AND   [CO2] IS NOT NULL\n",
					"   AND   [bio_HCB] IS NOT NULL\n",
					"   AND   [fossil_HCB] IS NOT NULL\n",
					"   AND   [NH3] IS NOT NULL\n",
					"   AND   [NMVOC] IS NOT NULL\n",
					"     AND [NOx] IS NOT NULL\n",
					"      AND [OC] IS NOT NULL\n",
					"      AND [bio_PAH_BaP] IS NOT NULL\n",
					"      AND [fossil_PAH_BaP] IS NOT NULL\n",
					"      AND [PAH_BbF] IS NOT NULL\n",
					"      AND [bio_PAH_IcdP] IS NOT NULL\n",
					"      AND [fossil_PAH_IcdP] IS NOT NULL\n",
					"      AND [bio_PAH_BkF] IS NOT NULL\n",
					"      AND [fossil_PAH_BbF] IS NOT NULL\n",
					"      AND [bio_PCB] IS NOT NULL\n",
					"      AND [fossil_PCB] IS NOT NULL\n",
					"      AND [bio_PCDD_F] IS NOT NULL\n",
					"      AND [fossil_PCDD_F] IS NOT NULL\n",
					"      AND[PM10] IS NOT NULL\n",
					"      AND [PM25] IS NOT NULL\n",
					"      AND [SO2] IS NOT NULL\n",
					"\t  AND\n",
					"  [GDP] IS NOT NULL\n",
					"      AND [GDP_per_capita] IS NOT NULL\n",
					"      AND [GDP_per_capita_growth] IS NOT NULL\n",
					"      AND [Gross_value_added] IS NOT NULL\n",
					"      AND [Life_expectancy_birth(years)] IS NOT NULL\n",
					"      AND [Access_electricity(%)] IS NOT NULL\n",
					"     -- AND [Broad_money] IS NOT NULL\n",
					"      AND [Agricultural_land] IS NOT NULL\n",
					"\n",
					"      --AND [Tax_revenue] IS NOT NULL\n",
					"      \n",
					"\t  AND [Services] IS NOT NULL\n",
					"\n",
					"\t        AND[Unemployment] IS NOT NULL\n",
					"      AND[Control_Corruption] IS NOT NULL\n",
					"      AND[Contributing_family] IS NOT NULL\n",
					"      AND[Government Effectiveness] IS NOT NULL\n",
					"      AND[Political_Stability] IS NOT NULL\n",
					"      AND[LAW] IS NOT NULL\n",
					"      AND[Regulatory_Quality] IS NOT NULL \"\"\""
				],
				"execution_count": 89
			},
			{
				"cell_type": "code",
				"source": [
					"# Socio x Clima\n",
					"connection = pyodbc.connect('DRIVER={SQL Server};SERVER=DESKTOP-6UKL08J;DATABASE=IncidenceDWH;Trusted_Connection=yes;')\n",
					"\n",
					"query = \"\"\"\n",
					"SELECT --[Name]\n",
					"      --[Year]\n",
					"\t        [GDP]\n",
					"      ,[GDP_per_capita]\n",
					"      ,[GDP_per_capita_growth]\n",
					"      ,[Gross_value_added]\n",
					"      ,[Life_expectancy_birth(years)]\n",
					"      ,[Access_electricity(%)]\n",
					"      ,[Agricultural_land]\n",
					"      ,[Services]\n",
					"      ,[Unemployment]\n",
					"      ,[Control_Corruption]\n",
					"      ,[Contributing_family]\n",
					"      ,[Government Effectiveness]\n",
					"      ,[Political_Stability]\n",
					"      ,[LAW]\n",
					"      ,[Regulatory_Quality]\n",
					"\n",
					"\t       ,[Weathercode]\n",
					"      ,[temperature_2m_max]\n",
					"      ,[temperature_2m_min]\n",
					"      ,[temperature_2m_mean]\n",
					"      ,[apparent_temperature_max]\n",
					"      ,[apparent_temperature_min]\n",
					"      ,[apparent_temperature_mean]\n",
					"      ,[precipitation_sum_mm]\n",
					"      ,[rain_sum_mm]\n",
					"      ,[snowfall_sum_cm]\n",
					"      ,[precipitation_hours_h]\n",
					"      ,[windspeed_10m_max_km/h]\n",
					"      ,[windgusts_10m_max_km/h]\n",
					"      ,[winddirection_10m_dominant]\n",
					"      ,[shortwave_radiation_sum]\n",
					"\n",
					"\t  , Value as Incidencia\n",
					"  FROM [IncidenceDWH].[dbo].[VectorTiempo] AS T\n",
					"  INNER JOIN [dbo].[factIncidences] AS I ON I.Location = T.Country AND I.Year = T.Year \n",
					"  INNER JOIN dbo.vectorSocio2 AS t1  ON I.Location = T1.Country AND I.Year = T1.Year \n",
					"  where i.ID_Cause = 573 and ID_Sex = 1\n",
					"  AND [GDP] IS NOT NULL\n",
					"      AND [GDP_per_capita] IS NOT NULL\n",
					"      AND [GDP_per_capita_growth] IS NOT NULL\n",
					"      AND [Gross_value_added] IS NOT NULL\n",
					"      AND [Life_expectancy_birth(years)] IS NOT NULL\n",
					"      AND [Access_electricity(%)] IS NOT NULL\n",
					"     -- AND [Broad_money] IS NOT NULL\n",
					"      AND [Agricultural_land] IS NOT NULL\n",
					"\n",
					"      --AND [Tax_revenue] IS NOT NULL\n",
					"      \n",
					"\t  AND [Services] IS NOT NULL\n",
					"\n",
					"\t        AND[Unemployment] IS NOT NULL\n",
					"      AND[Control_Corruption] IS NOT NULL\n",
					"      AND[Contributing_family] IS NOT NULL\n",
					"      AND[Government Effectiveness] IS NOT NULL\n",
					"      AND[Political_Stability] IS NOT NULL\n",
					"      AND[LAW] IS NOT NULL\n",
					"      AND[Regulatory_Quality] IS NOT NULL\"\"\" "
				],
				"execution_count": 95
			},
			{
				"cell_type": "code",
				"source": [
					"# 573 1 climaXsocio\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 96
			},
			{
				"cell_type": "code",
				"source": [
					"# 570 1 climaXsocio\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 94
			},
			{
				"cell_type": "code",
				"source": [
					"# 559 2 climaXsocio\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 92
			},
			{
				"cell_type": "code",
				"source": [
					"# 575 1 socioXquimicos\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 90
			},
			{
				"cell_type": "code",
				"source": [
					"# 570 2 socioXquimicos\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 88
			},
			{
				"cell_type": "code",
				"source": [
					"# 570 1 socioXquimicos\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 86
			},
			{
				"cell_type": "code",
				"source": [
					"# 568 1 socioXquimicos\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 84
			},
			{
				"cell_type": "code",
				"source": [
					"# 559 2 socioXquimicos\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 82
			},
			{
				"cell_type": "code",
				"source": [
					"# 559 1 socioXquimicos\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 80
			},
			{
				"cell_type": "code",
				"source": [
					"# 571 1 climaXquimicos\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 78
			},
			{
				"cell_type": "code",
				"source": [
					"# Terminar Clima x Quimicos  arriba"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"## Todo junto terminado"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# 575 1\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 76
			},
			{
				"cell_type": "code",
				"source": [
					"# 573 1\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 74
			},
			{
				"cell_type": "code",
				"source": [
					"# 570 1\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 72
			},
			{
				"cell_type": "code",
				"source": [
					"# 568 2\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias FutureWarning relacionadas con SequentialFeatureSelector\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.feature_selection\")\n",
					"\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 70
			},
			{
				"cell_type": "code",
				"source": [
					"## Junto"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# 568 1\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 61
			},
			{
				"cell_type": "code",
				"source": [
					"######## Quimicos abajo"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# 579 1\n",
					"\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 59
			},
			{
				"cell_type": "code",
				"source": [
					"# 574 2\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 57
			},
			{
				"cell_type": "code",
				"source": [
					"# 573 1\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 55
			},
			{
				"cell_type": "code",
				"source": [
					"# 570 2\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 53
			},
			{
				"cell_type": "code",
				"source": [
					"# 568 1\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 50
			},
			{
				"cell_type": "code",
				"source": [
					"# 559 1\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 48
			},
			{
				"cell_type": "code",
				"source": [
					"############################## Clima abajo"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# 569 2\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 42
			},
			{
				"cell_type": "code",
				"source": [
					"# 579 2\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 40
			},
			{
				"cell_type": "code",
				"source": [
					"# 575 1\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 37
			},
			{
				"cell_type": "code",
				"source": [
					"# 574 1\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 35
			},
			{
				"cell_type": "code",
				"source": [
					"# 570 2\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 33
			},
			{
				"cell_type": "code",
				"source": [
					"# 559 2\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 32
			},
			{
				"cell_type": "code",
				"source": [
					"# 559 1\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 30
			},
			{
				"cell_type": "code",
				"source": [
					"#568 2\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR()\n",
					"    #'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 28
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"import numpy as np\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SequentialFeatureSelector\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"import time\n",
					"from sklearn.pipeline import Pipeline\n",
					"import warnings\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"\n",
					"# Suprime la advertencia temporalmente\n",
					"warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"import warnings\n",
					"\n",
					"# Ignora las advertencias RuntimeWarning\n",
					"warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
					"\n",
					"# Cargar el DataFrame\n",
					"# df = pd.read_csv('tu_archivo.csv')  # Reemplaza 'tu_archivo.csv' con tu archivo de datos\n",
					"# Asumiendo que el DataFrame tiene una columna 'Incidencia' y el resto son características\n",
					"df = pd.read_sql(query, connection)\n",
					"# Separar las características (X) y la variable objetivo (y)\n",
					"X = df.drop('Incidencia', axis=1)\n",
					"y = df['Incidencia']\n",
					"\n",
					"# Dividir los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
					"\n",
					"# Crear un objeto StandardScaler para normalizar los datos\n",
					"scaler = StandardScaler()\n",
					"\n",
					"# Crear diccionarios para almacenar los modelos y sus nombres\n",
					"models = {\n",
					"    'Linear Regression': LinearRegression(),\n",
					"    'Decision Tree': DecisionTreeRegressor(),\n",
					"    'Random Forest': RandomForestRegressor(),\n",
					"    'SVM': SVR(),\n",
					"    'MLP': MLPRegressor()\n",
					"}\n",
					"\n",
					"# Lista de técnicas de selección de características\n",
					"feature_selectors = [\n",
					"    ('Original', None),\n",
					"    ('Variance Threshold', VarianceThreshold()),\n",
					"    ('Percentile', SelectPercentile()),\n",
					"    ('Backward Search', SequentialFeatureSelector(LinearRegression(), direction='backward'))\n",
					"]\n",
					"\n",
					"# Bucle principal para iterar a través de modelos y técnicas de selección de características\n",
					"for model_name, model in models.items():\n",
					"    for selector_name, selector in feature_selectors:\n",
					"        # Crear una lista de pasos para el pipeline (escalado y selección de características)\n",
					"        steps = [('scaler', scaler)]\n",
					"        if selector is not None:\n",
					"            steps.append(('feature_selector', selector))\n",
					"        \n",
					"        # Crear el pipeline con el modelo y los pasos de preprocesamiento\n",
					"        pipeline = Pipeline(steps + [('model', model)])\n",
					"        \n",
					"        # Realizar validación cruzada con KFold\n",
					"        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"        \n",
					"        #start_time = time.time()\n",
					"        # Calcular las métricas de evaluación durante la validación cruzada\n",
					"        rmse_scores = np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error'))\n",
					"        mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
					"        r2_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2')\n",
					"        #end_time = time.time()\n",
					"        \n",
					"        # Ajustar el modelo al conjunto de entrenamiento completo\n",
					"        pipeline.fit(X_train, y_train)\n",
					"        \n",
					"        # Predecir en el conjunto de prueba\n",
					"        y_pred = pipeline.predict(X_test)\n",
					"        \n",
					"        # Calcular las métricas de evaluación en el conjunto de prueba\n",
					"        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
					"        test_mae = mean_absolute_error(y_test, y_pred)\n",
					"        test_r2 = r2_score(y_test, y_pred)\n",
					"        \n",
					"        # Imprimir resultados\n",
					"        print(f'Modelo: {model_name}, Selector de Características: {selector_name}')\n",
					"        print(f'RMSE (Promedio durante CV): {rmse_scores.mean():.4f}')\n",
					"        print(f'MAE (Promedio durante CV): {mae_scores.mean():.4f}')\n",
					"        print(f'R2 (Promedio durante CV): {r2_scores.mean():.4f}')\n",
					"        #print(f'Tiempo de Ejecución (s): {end_time - start_time:.2f}')\n",
					"        print(f'Test RMSE: {test_rmse:.4f}')\n",
					"        print(f'Test MAE: {test_mae:.4f}')\n",
					"        print(f'Test R2: {test_r2:.4f}')\n",
					"        print('-' * 50)\n",
					""
				],
				"execution_count": 26
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectPercentile, f_regression, RFECV, chi2\n",
					"import numpy as np\n",
					"\n",
					"# Lee los datos desde la base de datos o tu fuente de datos\n",
					"df = pd.read_sql(query, connection)\n",
					"\n",
					"# Crea variables de características y la variable objetivo\n",
					"X = df.drop('incidencia', axis=1)\n",
					"y = df['incidencia']\n",
					"\n",
					"# Normaliza los valores de las características utilizando StandardScaler\n",
					"scaler = StandardScaler()\n",
					"X_scaled = scaler.fit_transform(X)\n",
					"\n",
					"# Divide los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=101)\n",
					"\n",
					"# Crea un modelo de regresión lineal\n",
					"model = LinearRegression()\n",
					"\n",
					"# Realiza la validación cruzada con K-Fold (en este caso, 5-Fold)\n",
					"kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"\n",
					"# Agrega el selector de características basado en la varianza\n",
					"variance_selector = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
					"X_variance_selected = variance_selector.fit_transform(X_scaled)\n",
					"\n",
					"# Agrega el selector de características basado en percentiles\n",
					"#percentile_selector = SelectPercentile(score_func=f_regression, percentile=10)\n",
					"percentile_selector = SelectPercentile(score_func=chi2, percentile=10)  # Cambia 'percentile' según el valor deseado\n",
					"X_percentile_selected = percentile_selector.fit_transform(X_scaled, y)\n",
					"\n",
					"# Agrega el enfoque de eliminación hacia atrás (backward search) con RFECV\n",
					"rfecv_selector = RFECV(estimator=model, cv=kf, scoring='neg_mean_squared_error')  # Puedes cambiar la métrica\n",
					"X_rfecv_selected = rfecv_selector.fit_transform(X_scaled, y)\n",
					"\n",
					"# Ajusta el modelo de regresión lineal utilizando las características seleccionadas por cada método\n",
					"models = {\n",
					"    'Original Features': model.fit(X_train, y_train),\n",
					"    'Variance Selected': model.fit(X_variance_selected, y),\n",
					"    'Percentile Selected': model.fit(X_percentile_selected, y),\n",
					"    'RFECV Selected': model.fit(X_rfecv_selected, y)\n",
					"}\n",
					"\n",
					"# Evalúa los modelos y muestra las métricas\n",
					"for model_name, fitted_model in models.items():\n",
					"    if model_name == 'Original Features':\n",
					"        X_test_selected = X_test  # No se seleccionan características para el modelo original\n",
					"    elif model_name == 'Variance Selected':\n",
					"        X_test_selected = variance_selector.transform(X_test)\n",
					"    elif model_name == 'Percentile Selected':\n",
					"        X_test_selected = percentile_selector.transform(X_test)\n",
					"    elif model_name == 'RFECV Selected':\n",
					"        X_test_selected = rfecv_selector.transform(X_test)\n",
					"    \n",
					"    # Asegúrate de que el número de características coincida con las del modelo\n",
					"    if X_test_selected.shape[1] != X_train.shape[1]:\n",
					"        print(f'El número de características seleccionadas para {model_name} no coincide con el modelo original.')\n",
					"    else:\n",
					"        predictions = fitted_model.predict(X_test_selected)\n",
					"        mse = mean_squared_error(y_test, predictions)\n",
					"        mae = mean_absolute_error(y_test, predictions)\n",
					"        rmse = np.sqrt(mse)\n",
					"        r2 = r2_score(y_test, predictions)\n",
					"        \n",
					"        print(f'Model: {model_name}')\n",
					"        print('Mean Squared Error (MSE): ', mse)\n",
					"        print('Mean Absolute Error (MAE): ', mae)\n",
					"        print('Root Mean Squared Error (RMSE): ', rmse)\n",
					"        print('R^2 Score: ', r2)\n",
					"        print('---')"
				],
				"execution_count": 22
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"\n",
					"# Lee los datos desde la base de datos o tu fuente de datos\n",
					"df = pd.read_sql(query, connection)\n",
					"\n",
					"# Crea variables de características y la variable objetivo\n",
					"X = df.drop('incidencia', axis=1)\n",
					"y = df['incidencia']\n",
					"\n",
					"# Normaliza los valores de las características utilizando StandardScaler\n",
					"scaler = StandardScaler()\n",
					"X_scaled = scaler.fit_transform(X)\n",
					"\n",
					"# Divide los datos en conjuntos de entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=101)\n",
					"\n",
					"# Crea un modelo de regresión lineal\n",
					"model = LinearRegression()\n",
					"\n",
					"# Realiza la validación cruzada con K-Fold (en este caso, 5-Fold)\n",
					"kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
					"\n",
					"# Calcula las métricas de rendimiento para cada fold\n",
					"mse_scores = -cross_val_score(model, X_scaled, y, cv=kf, scoring='neg_mean_squared_error')\n",
					"mae_scores = -cross_val_score(model, X_scaled, y, cv=kf, scoring='neg_mean_absolute_error')\n",
					"r2_scores = cross_val_score(model, X_scaled, y, cv=kf, scoring='r2')\n",
					"\n",
					"# Calcula la métrica RMSE para cada fold\n",
					"rmse_scores = (mse_scores.mean()) ** 0.5\n",
					"\n",
					"# Imprime todas las métricas\n",
					"print('Mean MSE: ', mse_scores.mean())\n",
					"print('Mean MAE: ', mae_scores.mean())\n",
					"print('Mean RMSE: ', rmse_scores)\n",
					"print('Mean R^2: ', r2_scores.mean())\n",
					""
				],
				"execution_count": 17
			},
			{
				"cell_type": "code",
				"source": [
					"# Establece la conexión con la base de datos SQL Server\n",
					"#connection = pyodbc.connect('DRIVER={SQL Server};SERVER=NombreDelServidor;DATABASE=NombreDeLaBaseDeDatos;Trusted_Connection=yes;')\n",
					"\n",
					"resultado = []\n",
					"\n",
					"for i in range(5):\n",
					"    # Carga los datos en un DataFrame\n",
					"    data = pd.read_sql(query, connection)\n",
					"\n",
					"    # División de datos en entrenamiento y prueba\n",
					"    X = data.drop('incidencia', axis=1)\n",
					"    y = data['incidencia']\n",
					"    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
					"\n",
					"    # Creación y entrenamiento del modelo de regresión lineal\n",
					"    model = LinearRegression()\n",
					"    model.fit(X_train, y_train)\n",
					"\n",
					"    # Predicciones en el conjunto de prueba\n",
					"    y_pred = model.predict(X_test)\n",
					"\n",
					"    # Evaluación del modelo\n",
					"    mse = mean_squared_error(y_test, y_pred)\n",
					"    r2 = r2_score(y_test, y_pred)\n",
					"\n",
					"    print(f'Mean Squared Error: {mse}')\n",
					"    print(f'R-squared: {r2}')\n",
					"    resultado.append(r2)\n",
					"print(\"....\")\n",
					"mean = sum(resultado)/len(resultado)\n",
					"print(mean)"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"from sklearn.model_selection import train_test_split, KFold\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
					"import pyodbc\n",
					"\n",
					"# Ridge() o Lasso() sklearn.linear_model\n",
					"# DecisionTreeRegressor() sklearn.tree\n",
					"# RandomForestRegressor() de sklearn.ensemble\n",
					"# SVR() sklearn.svm\n",
					"# MLPRegressor() sklearn.neural_network\n",
					"from sklearn.linear_model import Ridge, Lasso\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.feature_selection import RFE\n",
					"from sklearn.feature_selection import SelectFromModel\n",
					"from sklearn.linear_model import LogisticRegression\n",
					"\n",
					"from sklearn.feature_selection import VarianceThreshold\n",
					"from sklearn import preprocessing\n",
					"\n",
					"\n",
					"from sklearn.feature_selection import VarianceThreshold\n",
					"from sklearn.feature_selection import SelectKBest\n",
					"from sklearn.feature_selection import chi2\n",
					"# chi2_selector = SelectKBest(chi2, k=2)\n",
					"# X_kbest = chi2_selector.fit_transform(X, y)\n",
					"from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
					"from sklearn.metrics import roc_auc_score \n",
					"from mlxtend.feature_selection import SequentialFeatureSelector \n",
					"# feature_selector = SequentialFeatureSelector(RandomForestClassifier(n_jobs=-1),\n",
					"#                           k_features=15, forward=False, \n",
					"#                           verbose=2, scoring=’roc_auc’, cv=4)"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"connection = pyodbc.connect('DRIVER={SQL Server};SERVER=DESKTOP-6UKL08J;DATABASE=IncidenceDWH;Trusted_Connection=yes;')\n",
					"\n",
					"# Consulta para obtener los datos climáticos y de incidencia de enfermedad\n",
					"query1 = \"\"\"\n",
					"SELECT --[Country],\n",
					"      --t.[Year],\n",
					"      [Weathercode]\n",
					"      ,[temperature_2m_max]\n",
					"      ,[temperature_2m_min]\n",
					"      ,[temperature_2m_mean]\n",
					"      ,[apparent_temperature_max]\n",
					"      ,[apparent_temperature_min]\n",
					"      ,[apparent_temperature_mean]\n",
					"      ,[precipitation_sum_mm]\n",
					"      ,[rain_sum_mm]\n",
					"      ,[snowfall_sum_cm]\n",
					"      ,[precipitation_hours_h]\n",
					"      ,[windspeed_10m_max_km/h]\n",
					"      ,[windgusts_10m_max_km/h]\n",
					"      ,[winddirection_10m_dominant]\n",
					"      ,[shortwave_radiation_sum]\n",
					"\t  , Value as incidencia\n",
					"\t  , GDP\n",
					"\t  ,GDP_per_capita\n",
					"\t  ,CO2_emissions\n",
					"  FROM [IncidenceDWH].[dbo].[VectorTiempo] AS T\n",
					"  INNER JOIN [dbo].[factIncidences] AS I ON I.Location = T.Country AND I.Year = T.Year \n",
					"  INNER JOIN vectorPib AS P ON P.Location = T.Country AND P.Year = T.Year \n",
					"  where i.ID_Cause = 568 \n",
					"  AND ID_Sex = 1\n",
					"  AND GDP NOT LIKE '..' AND GDP_per_capita NOT LIKE '..'  AND CO2_emissions NOT LIKE '..' \"\"\"\n",
					"query2 = \"\"\"\n",
					"SELECT --[Country],\n",
					"      --t.[Year],\n",
					"      [Weathercode]\n",
					"      ,[temperature_2m_max]\n",
					"      ,[temperature_2m_min]\n",
					"      ,[temperature_2m_mean]\n",
					"      ,[apparent_temperature_max]\n",
					"      ,[apparent_temperature_min]\n",
					"      ,[apparent_temperature_mean]\n",
					"      ,[precipitation_sum_mm]\n",
					"      ,[rain_sum_mm]\n",
					"      ,[snowfall_sum_cm]\n",
					"      ,[precipitation_hours_h]\n",
					"      ,[windspeed_10m_max_km/h]\n",
					"      ,[windgusts_10m_max_km/h]\n",
					"      ,[winddirection_10m_dominant]\n",
					"      ,[shortwave_radiation_sum]\n",
					"\t  , Value as incidencia\n",
					"\t  , GDP\n",
					"\t  ,GDP_per_capita\n",
					"\t  ,CO2_emissions\n",
					"  FROM [IncidenceDWH].[dbo].[VectorTiempo] AS T\n",
					"  INNER JOIN [dbo].[factIncidences] AS I ON I.Location = T.Country AND I.Year = T.Year \n",
					"  INNER JOIN vectorPib AS P ON P.Location = T.Country AND P.Year = T.Year \n",
					"  where i.ID_Cause = 571 --568\n",
					"  AND ID_Sex = 2\n",
					"   AND GDP NOT LIKE '..' AND GDP_per_capita NOT LIKE '..'  AND CO2_emissions NOT LIKE '..' \"\"\""
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"import numpy as np\n",
					"import matplotlib.pyplot as plt\n",
					"import seaborn as sns\n",
					"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.neural_network import MLPRegressor\n",
					"from sklearn.tree import DecisionTreeRegressor\n",
					"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression, SequentialFeatureSelector\n",
					"from mlxtend.feature_selection import SequentialFeatureSelector\n",
					"from warnings import simplefilter\n",
					"import sys\n",
					"from sklearn.exceptions import ConvergenceWarning\n",
					"import pyodbc"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"source": [
					"query1 = \"\"\"SELECT -- [Country]\n",
					"     -- ,t.[Year],\n",
					"      [Weathercode]\n",
					"      ,[temperature_2m_max]\n",
					"      ,[temperature_2m_min]\n",
					"      ,[temperature_2m_mean]\n",
					"      ,[apparent_temperature_max]\n",
					"      ,[apparent_temperature_min]\n",
					"      ,[apparent_temperature_mean]\n",
					"      ,[precipitation_sum_mm]\n",
					"      ,[rain_sum_mm]\n",
					"      ,[snowfall_sum_cm]\n",
					"      ,[precipitation_hours_h]\n",
					"      ,[windspeed_10m_max_km/h]\n",
					"      ,[windgusts_10m_max_km/h]\n",
					"      ,[winddirection_10m_dominant]\n",
					"      ,[shortwave_radiation_sum]\n",
					"\t\t, Value as incidencia\n",
					"\n",
					"  FROM [IncidenceDWH].[dbo].[VectorTiempo] AS T\n",
					"  INNER JOIN [dbo].[factIncidences] AS I ON I.Location = T.Country AND I.Year = T.Year \n",
					"  --INNER JOIN vectorPib AS P ON P.Location = T.Country AND P.Year = T.Year \n",
					"  where i.ID_Cause = 559 \n",
					"  AND ID_Sex = 1\"\"\"\n",
					"\n",
					"connection = pyodbc.connect('DRIVER={SQL Server};SERVER=DESKTOP-6UKL08J;DATABASE=IncidenceDWH;Trusted_Connection=yes;')\n",
					""
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"# Ignorar el aviso de convergencia para el MLPRegressor\n",
					"simplefilter(\"ignore\", category=ConvergenceWarning)\n",
					"\n",
					"# importing data\n",
					"# df = pd.read_csv('Real estate.csv')\n",
					"df = pd.read_sql(query1, connection)\n",
					"\n",
					"# creating feature variables\n",
					"X = df.drop('incidencia', axis=1)\n",
					"y = df['incidencia']\n",
					"\n",
					"# creating train and test sets\n",
					"X_train, X_test, y_train, y_test = train_test_split(\n",
					"    X, y, test_size=0.3, random_state=101)\n",
					"\n",
					"# creating a list of models\n",
					"models = [\n",
					"    ('Linear Regression', LinearRegression()),\n",
					"    ('Decision Tree', DecisionTreeRegressor()),\n",
					"    ('Random Forest', RandomForestRegressor()),\n",
					"    ('SVR', SVR()),  # Support Vector Machine\n",
					"    ('MLP', MLPRegressor())  # Limit MLP to 1 iteration to suppress warning\n",
					"]\n",
					"\n",
					"# Standardize features\n",
					"scaler = StandardScaler()\n",
					"X_train_scaled = scaler.fit_transform(X_train)\n",
					"X_test_scaled = scaler.transform(X_test)\n",
					"\n",
					"# Variance-based feature selection\n",
					"selector_variance = VarianceThreshold()\n",
					"X_train_variance = selector_variance.fit_transform(X_train_scaled)\n",
					"X_test_variance = selector_variance.transform(X_test_scaled)\n",
					"\n",
					"# Univariate feature selection (k-best)\n",
					"selector_kbest = SelectKBest(score_func=f_regression, k=5)  # Adjust 'k' as needed\n",
					"X_train_kbest = selector_kbest.fit_transform(X_train_scaled, y_train)\n",
					"X_test_kbest = selector_kbest.transform(X_test_scaled)\n",
					"\n",
					"# Model training and evaluation with Variance-Based Selection\n",
					"print(\"Variance-Based Feature Selection:\")\n",
					"for name, model in models:\n",
					"    kfold = KFold(n_splits=5, shuffle=True, random_state=101)\n",
					"    cv_mse = -cross_val_score(model, X_train_variance, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
					"    cv_mae = -cross_val_score(model, X_train_variance, y_train, cv=kfold, scoring='neg_mean_absolute_error')\n",
					"    cv_r2 = cross_val_score(model, X_train_variance, y_train, cv=kfold, scoring='r2')\n",
					"\n",
					"    model.fit(X_train_variance, y_train)\n",
					"    predictions = model.predict(X_test_variance)\n",
					"\n",
					"    mse = mean_squared_error(y_test, predictions)\n",
					"    rmse = np.sqrt(mse)  # Calculate RMSE\n",
					"\n",
					"    print(f'Model: {name}')\n",
					"    print(f'Cross-validated MSE: {cv_mse.mean()}')\n",
					"    print(f'Cross-validated MAE: {cv_mae.mean()}')\n",
					"    print(f'Cross-validated R^2: {cv_r2.mean()}')\n",
					"    print(f'Test MSE: {mse}')\n",
					"    print(f'Test RMSE: {rmse}')  # Print RMSE\n",
					"    print(f'Test MAE: {mean_absolute_error(y_test, predictions)}')\n",
					"    print(f'Test R^2: {r2_score(y_test, predictions)}')\n",
					"    print('---')\n",
					"\n",
					"# Model training and evaluation with k-best Selection\n",
					"print(\"k-best Feature Selection:\")\n",
					"for name, model in models:\n",
					"    kfold = KFold(n_splits=5, shuffle=True, random_state=101)\n",
					"    cv_mse = -cross_val_score(model, X_train_kbest, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
					"    cv_mae = -cross_val_score(model, X_train_kbest, y_train, cv=kfold, scoring='neg_mean_absolute_error')\n",
					"    cv_r2 = cross_val_score(model, X_train_kbest, y_train, cv=kfold, scoring='r2')\n",
					"\n",
					"    model.fit(X_train_kbest, y_train)\n",
					"    predictions = model.predict(X_test_kbest)\n",
					"\n",
					"    mse = mean_squared_error(y_test, predictions)\n",
					"    rmse = np.sqrt(mse)  # Calculate RMSE\n",
					"\n",
					"    print(f'Model: {name}')\n",
					"    print(f'Cross-validated MSE: {cv_mse.mean()}')\n",
					"    print(f'Cross-validated MAE: {cv_mae.mean()}')\n",
					"    print(f'Cross-validated R^2: {cv_r2.mean()}')\n",
					"    print(f'Test MSE: {mse}')\n",
					"    print(f'Test RMSE: {rmse}')  # Print RMSE\n",
					"    print(f'Test MAE: {mean_absolute_error(y_test, predictions)}')\n",
					"    print(f'Test R^2: {r2_score(y_test, predictions)}')\n",
					"    print('---')\n",
					"\n",
					"# Model training and evaluation with Sequential Feature Selector (Backward Selection)\n",
					"print(\"Sequential Feature Selector (Backward Selection):\")\n",
					"for name, model in models:\n",
					"    kfold = KFold(n_splits=5, shuffle=True, random_state=101)\n",
					"\n",
					"    # Create a Sequential Feature Selector object for backward selection\n",
					"    sfs = SequentialFeatureSelector(model, k_features=5, forward=False, scoring='neg_mean_squared_error', cv=kfold)\n",
					"\n",
					"    # Fit the selector to the training data\n",
					"    sfs.fit(X_train_scaled, y_train)\n",
					"\n",
					"    # Get the selected feature indices\n",
					"    selected_indices = list(sfs.k_feature_idx_)\n",
					"\n",
					"    # Subset the training and test data based on selected features\n",
					"    X_train_sfs = X_train_scaled[:, selected_indices]\n",
					"    X_test_sfs = X_test_scaled[:, selected_indices]\n",
					"\n",
					"    # Cross-validation\n",
					"    cv_mse = -cross_val_score(model, X_train_sfs, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
					"    cv_mae = -cross_val_score(model, X_train_sfs, y_train, cv=kfold, scoring='neg_mean_absolute_error')\n",
					"    cv_r2 = cross_val_score(model, X_train_sfs, y_train, cv=kfold, scoring='r2')\n",
					"\n",
					"    # Model training and evaluation\n",
					"    model.fit(X_train_sfs, y_train)\n",
					"    predictions = model.predict(X_test_sfs)\n",
					"\n",
					"    mse = mean_squared_error(y_test, predictions)\n",
					"    rmse = np.sqrt(mse)  # Calculate RMSE\n",
					"\n",
					"    print(f'Model: {name}')\n",
					"    print(f'Selected Features: {selected_indices}')\n",
					"    print(f'Cross-validated MSE: {cv_mse.mean()}')\n",
					"    print(f'Cross-validated MAE: {cv_mae.mean()}')\n",
					"    print(f'Cross-validated R^2: {cv_r2.mean()}')\n",
					"    print(f'Test MSE: {mse}')\n",
					"    print(f'Test RMSE: {rmse}')  # Print RMSE\n",
					"    print(f'Test MAE: {mean_absolute_error(y_test, predictions)}')\n",
					"    print(f'Test R^2: {r2_score(y_test, predictions)}')\n",
					"    print('---')\n",
					"\n",
					"# Model training and evaluation without feature selection\n",
					"print(\"No Feature Selection:\")\n",
					"for name, model in models:\n",
					"    kfold = KFold(n_splits=5, shuffle=True, random_state=101)\n",
					"    cv_mse = -cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
					"    cv_mae = -cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='neg_mean_absolute_error')\n",
					"    cv_r2 = cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='r2')\n",
					"\n",
					"    model.fit(X_train_scaled, y_train)\n",
					"    predictions = model.predict(X_test_scaled)\n",
					"\n",
					"    mse = mean_squared_error(y_test, predictions)\n",
					"    rmse = np.sqrt(mse)  # Calculate RMSE\n",
					"\n",
					"    print(f'Model: {name}')\n",
					"    print(f'Cross-validated MSE: {cv_mse.mean()}')\n",
					"    print(f'Cross-validated MAE: {cv_mae.mean()}')\n",
					"    print(f'Cross-validated R^2: {cv_r2.mean()}')\n",
					"    print(f'Test MSE: {mse}')\n",
					"    print(f'Test RMSE: {rmse}')  # Print RMSE\n",
					"    print(f'Test MAE: {mean_absolute_error(y_test, predictions)}')\n",
					"    print(f'Test R^2: {r2_score(y_test, predictions)}')\n",
					"    print('---')\n",
					""
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"source": [
					"# importing data\n",
					"# df = pd.read_csv('Real estate.csv')\n",
					"df = pd.read_sql(query1, connection)\n",
					"  \n",
					"# creating feature variables\n",
					"X = df.drop('incidencia', axis=1)\n",
					"y = df['incidencia']\n",
					"  \n",
					"# creating train and test sets\n",
					"X_train, X_test, y_train, y_test = train_test_split(\n",
					"    X, y, test_size=0.3, random_state=101)\n",
					"  \n",
					"# creating a list of models\n",
					"models = [\n",
					"    ('Linear Regression', LinearRegression()),\n",
					"    ('Decision Tree', DecisionTreeRegressor()),\n",
					"    ('Random Forest', RandomForestRegressor()),\n",
					"    ('SVR', SVR()),  # Support Vector Machine\n",
					"    ('MLP', MLPRegressor())\n",
					"]\n",
					"\n",
					"# Standardize features\n",
					"scaler = StandardScaler()\n",
					"X_train_scaled = scaler.fit_transform(X_train)\n",
					"X_test_scaled = scaler.transform(X_test)\n",
					"\n",
					"# Variance-based feature selection\n",
					"selector = VarianceThreshold()\n",
					"X_train_selected = selector.fit_transform(X_train_scaled)\n",
					"X_test_selected = selector.transform(X_test_scaled)\n",
					"\n",
					"# Model training and evaluation\n",
					"for name, model in models:\n",
					"    kfold = KFold(n_splits=5, shuffle=True, random_state=101)\n",
					"    cv_mse = -cross_val_score(model, X_train_selected, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
					"    cv_mae = -cross_val_score(model, X_train_selected, y_train, cv=kfold, scoring='neg_mean_absolute_error')\n",
					"    cv_r2 = cross_val_score(model, X_train_selected, y_train, cv=kfold, scoring='r2')\n",
					"    \n",
					"    model.fit(X_train_selected, y_train)\n",
					"    predictions = model.predict(X_test_selected)\n",
					"    \n",
					"    print(f'Model: {name}')\n",
					"    print(f'Cross-validated MSE: {cv_mse.mean()}')\n",
					"    print(f'Cross-validated MAE: {cv_mae.mean()}')\n",
					"    print(f'Cross-validated R^2: {cv_r2.mean()}')\n",
					"    print(f'Test MSE: {mean_squared_error(y_test, predictions)}')\n",
					"    print(f'Test MAE: {mean_absolute_error(y_test, predictions)}')\n",
					"    print(f'Test R^2: {r2_score(y_test, predictions)}')\n",
					"    print('---')\n",
					""
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"source": [
					"## Aqui\n",
					"\n",
					"# import pandas as pd\n",
					"# import numpy as np\n",
					"# import matplotlib.pyplot as plt\n",
					"# import seaborn as sns\n",
					"# from sklearn.model_selection import train_test_split\n",
					"# from sklearn.linear_model import LinearRegression\n",
					"# from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score\n",
					"# from sklearn import preprocessing\n",
					"  \n",
					"# importing data\n",
					"#df = pd.read_csv('Real estate.csv')\n",
					"df = pd.read_sql(query, connection)\n",
					"  \n",
					"# creating feature variables\n",
					"X = df.drop('incidencia', axis=1)\n",
					"y = df['incidencia']\n",
					"\n",
					"# X = data.drop('incidencia', axis=1)\n",
					"# y = data['incidencia']\n",
					"\n",
					"#print(X)\n",
					"#print(y)\n",
					"  \n",
					"# creating train and test sets\n",
					"X_train, X_test, y_train, y_test = train_test_split(\n",
					"    X, y, test_size=0.3, random_state=101)\n",
					"  \n",
					"# creating a regression model\n",
					"model = LinearRegression()\n",
					"model2 = DecisionTreeRegressor()\n",
					"  \n",
					"# fitting the model\n",
					"model.fit(X_train, y_train)\n",
					"model2.fit(X_train, y_train)\n",
					"# making predictions\n",
					"predictions = model.predict(X_test)\n",
					"predictions2 = model2.predict(X_test) \n",
					"\n",
					"# model evaluation\n",
					"print('mean_squared_error : ', mean_squared_error(y_test, predictions))\n",
					"print('mean_absolute_error : ', mean_absolute_error(y_test, predictions))\n",
					"print('r2 : ', r2_score(y_test, predictions))\n",
					"#print('accuracy : ', accuracy_score(y_test, predictions))\n",
					"print(\"-----\")\n",
					"print('mean_squared_error : ', mean_squared_error(y_test, predictions2))\n",
					"print('mean_absolute_error : ', mean_absolute_error(y_test, predictions2))\n",
					"print('r2 : ', r2_score(y_test, predictions2))\n",
					"#print('accuracy : ', accuracy_score(y_test, predictions2))"
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"source": [
					"# Con kfold\n",
					"\n",
					"data = pd.read_sql(query1, connection)\n",
					"data2 = pd.read_sql(query2, connection)\n",
					"\n",
					"# data = preprocessing.normalize(data, norm='l1')\n",
					"# data2 = preprocessing.normalize(data2, norm='l1')\n",
					"# ... (Conexión a la base de datos y carga de datos como se muestra en el código anterior)\n",
					"X = data.drop('incidencia', axis=1)\n",
					"y = data['incidencia']\n",
					"\n",
					"\n",
					"\n",
					"X2 = data2.drop('incidencia', axis=1)\n",
					"y2 = data2['incidencia']\n",
					"\n",
					"\n",
					"X = preprocessing.normalize(X, norm='l1')\n",
					"y = preprocessing.normalize(y, norm='l1')\n",
					"\n",
					"X2 = preprocessing.normalize(X2, norm='l1')\n",
					"y2 = preprocessing.normalize(y2, norm='l1')\n",
					"\n",
					"# Creación del objeto KFold\n",
					"n_splits = 5  # Número de divisiones para K-Fold\n",
					"kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
					"\n",
					"scaler = StandardScaler()\n",
					"sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
					"#sel.fit_transform(X)\n",
					"\n",
					"# Lista para almacenar las métricas de evaluación en cada fold\n",
					"mse_scores = []\n",
					"r2_scores = []\n",
					"mean_absolute_error_score = []\n",
					"\n",
					"# Ciclo de K-Fold cross-validation\n",
					"for train_index, test_index in kf.split(X):\n",
					"    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
					"    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
					"    \n",
					"    # Ajustar el scaler en el conjunto de entrenamiento y aplicarlo a ambos conjuntos\n",
					"    # X_train_scaled = scaler.fit_transform(X_train)\n",
					"    # X_test_scaled = scaler.transform(X_test)\n",
					"\n",
					"    X_train_scaled = sel.fit_transform(X_train) #scaleer.fit\n",
					"    X_test_scaled = sel.transform(X_test)\n",
					"\n",
					"    # Creación y entrenamiento del modelo de regresión lineal para cada fold\n",
					"    #model = LinearRegression()\n",
					"    #model = LogisticRegression()\n",
					"    #model = Ridge() \n",
					"    #model = Lasso()\n",
					"    model = DecisionTreeRegressor()\n",
					"    #model = RandomForestRegressor()\n",
					"    #model = SVR()\n",
					"    #model = MLPRegressor()\n",
					"\n",
					"    #model.fit(X_train, y_train)\n",
					"    model.fit(X_train_scaled, y_train)\n",
					"    \n",
					"    # Predicciones en el conjunto de prueba\n",
					"    #y_pred = model.predict(X_test)\n",
					"    y_pred = model.predict(X_test_scaled)\n",
					"    \n",
					"    # Evaluación del modelo y almacenamiento de métricas\n",
					"\n",
					"    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
					"    r2_scores.append(r2_score(y_test, y_pred))\n",
					"    mean_absolute_error_score.append(mean_absolute_error(y_test, y_pred))\n",
					"\n",
					"# Cálculo de las métricas promedio\n",
					"average_mse = sum(mse_scores) / n_splits\n",
					"average_r2 = sum(r2_scores) / n_splits\n",
					"average_mean_absolute_error = sum(mean_absolute_error_score) / n_splits\n",
					"\n",
					"\n",
					"print(f'Average Mean Squared Error Males: {average_mse}')\n",
					"print(f'Average R-squared Males: {average_r2}')\n",
					"print(f'Average R-squared Males: {average_mean_absolute_error}')\n",
					"\n",
					"mse_scores = []\n",
					"r2_scores = []\n",
					"mean_absolute_error_score = []\n",
					"\n",
					"for train_index, test_index in kf.split(X2):\n",
					"    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
					"    y_train, y_test = y2.iloc[train_index], y2.iloc[test_index]\n",
					"    \n",
					"    # Ajustar el scaler en el conjunto de entrenamiento y aplicarlo a ambos conjuntos\n",
					"    X_train_scaled = scaler.fit_transform(X_train)\n",
					"    X_test_scaled = scaler.transform(X_test)\n",
					"\n",
					"    # Creación y entrenamiento del modelo de regresión lineal para cada fold\n",
					"    #model = LinearRegression()\n",
					"    #model = LogisticRegression()\n",
					"    #model = Ridge() \n",
					"    #model = Lasso()\n",
					"    model = DecisionTreeRegressor()\n",
					"    #model = RandomForestRegressor()\n",
					"    #model = SVR()\n",
					"    #model = MLPRegressor()\n",
					"\n",
					"    #model.fit(X_train, y_train)\n",
					"    model.fit(X_train_scaled, y_train)\n",
					"    \n",
					"    # Predicciones en el conjunto de prueba\n",
					"    #y_pred = model.predict(X_test)\n",
					"    y_pred = model.predict(X_test_scaled)\n",
					"    \n",
					"    # Evaluación del modelo y almacenamiento de métricas\n",
					"    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
					"    r2_scores.append(r2_score(y_test, y_pred))\n",
					"    mean_absolute_error_score.append(mean_absolute_error(y_test, y_pred))\n",
					"#aaaaaa\n",
					"# Cálculo de las métricas promedio\n",
					"average_mse = sum(mse_scores) / n_splits\n",
					"average_r2 = sum(r2_scores) / n_splits\n",
					"average_mean_absolute_error = sum(mean_absolute_error_score) / n_splits\n",
					"\n",
					"\n",
					"print(f'Average Mean Squared Error Males: {average_mse}')\n",
					"print(f'Average R-squared Males: {average_r2}')\n",
					"print(f'Average Mean Absolute rror: {average_mean_absolute_error}')"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"source": [
					"from sklearn.feature_selection import SelectFromModel\n",
					"from sklearn.preprocessing import StandardScaler\n",
					"from sklearn.linear_model import LinearRegression\n",
					"from sklearn.ensemble import RandomForestRegressor\n",
					"from sklearn.svm import SVR\n",
					"from sklearn.datasets import make_regression\n",
					"from sklearn.model_selection import train_test_split\n",
					"import pandas as pd\n",
					"\n",
					"# Crear datos de ejemplo\n",
					"#X, y = make_regression(n_samples=100, n_features=20, random_state=42)\n",
					"\n",
					"data = pd.read_sql(query, connection)\n",
					"# ... (Conexión a la base de datos y carga de datos como se muestra en el código anterior)\n",
					"X = data.drop('incidencia', axis=1)\n",
					"y = data['incidencia']\n",
					"\n",
					"\n",
					"# Dividir datos en entrenamiento y prueba\n",
					"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
					"\n",
					"# Crear un modelo para evaluar la importancia de las características\n",
					"model = RandomForestRegressor()  # Puedes usar otros modelos como LinearRegression, SVR, etc.\n",
					"\n",
					"# Crear un objeto SelectFromModel para realizar la selección\n",
					"selector = SelectFromModel(model)\n",
					"\n",
					"# Aplicar el selector en el conjunto de entrenamiento\n",
					"X_train_selected = selector.fit_transform(X_train, y_train)\n",
					"\n",
					"# Obtener las características seleccionadas\n",
					"selected_features = X_train.columns[selector.get_support()]\n",
					"\n",
					"# Imprimir las características seleccionadas\n",
					"print(\"Características seleccionadas:\")\n",
					"print(selected_features)"
				],
				"execution_count": 50
			}
		]
	}
}