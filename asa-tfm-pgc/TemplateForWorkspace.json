{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Nombre del Ã¡rea de trabajo",
			"defaultValue": "asa-tfm-pgc"
		},
		"asa-tfm-pgc-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Cadena protegida para \"connectionString\"de \"asa-tfm-pgc-WorkspaceDefaultSqlServer\"",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:asa-tfm-pgc.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"ls_ADLG2_Bronze_Landing_accountKey": {
			"type": "secureString",
			"metadata": "Cadena protegida para \"accountKey\"de \"ls_ADLG2_Bronze_Landing\""
		},
		"ls_COLI_ERP_password": {
			"type": "secureString",
			"metadata": "Cadena protegida para \"password\"de \"ls_COLI_ERP\""
		},
		"asa-tfm-pgc-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://datalake1pgc.dfs.core.windows.net"
		},
		"ls_ADLG2_Bronze_Landing_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://datalake1pgc.dfs.core.windows.net/"
		},
		"ls_COLI_ERP_properties_typeProperties_server": {
			"type": "string",
			"defaultValue": "@{linkedService().NombreServidor}"
		},
		"ls_COLI_ERP_properties_typeProperties_database": {
			"type": "string",
			"defaultValue": "@{linkedService().NombreBaseDatos}"
		},
		"ls_COLI_ERP_properties_typeProperties_userName": {
			"type": "string",
			"defaultValue": "sa"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/1 - SqlToLanding')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Listado tablas a cargar",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "Clean Landing",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": false,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"dataset": {
								"referenceName": "csvConfiguration",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "Copiar Origen a Destino",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Listado tablas a cargar",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Listado tablas a cargar').output.value",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "Active For Load",
									"type": "IfCondition",
									"dependsOn": [],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@not(equals(trim(item().Load), 'N'))",
											"type": "Expression"
										},
										"ifTrueActivities": [
											{
												"name": "Carga Landing",
												"type": "Copy",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 0,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"source": {
														"type": "SqlServerSource",
														"sqlReaderQuery": {
															"value": "SELECT *, @{formatDateTime(pipeline().TriggerTime,'yyyyMMdd')} AS fechaCarga, '@{pipeline().RunId}' AS pipelineID \nFROM @{item().SchemaName}.@{item().TableName} \nWHERE @{item().IncrementalColumn}>= CAST(CAST(@{item().UpdateDate} AS nvarchar) AS datetime2);",
															"type": "Expression"
														},
														"queryTimeout": "02:00:00",
														"partitionOption": "None"
													},
													"sink": {
														"type": "ParquetSink",
														"storeSettings": {
															"type": "AzureBlobFSWriteSettings",
															"copyBehavior": "FlattenHierarchy"
														},
														"formatSettings": {
															"type": "ParquetWriteSettings"
														}
													},
													"enableStaging": false,
													"parallelCopies": 1,
													"dataIntegrationUnits": 4,
													"translator": {
														"type": "TabularTranslator",
														"typeConversion": true,
														"typeConversionSettings": {
															"allowDataTruncation": true,
															"treatBooleanAsNumber": false
														}
													}
												},
												"inputs": [
													{
														"referenceName": "dsSQLGenerico",
														"type": "DatasetReference",
														"parameters": {
															"NombreServidor": "@item().ServerName",
															"NombreBD": "@item().DataBaseName",
															"NombreEsquema": "@item().SchemaName",
															"NombreTabla": "@item().TableName",
															"FechaActualizacion": "@item().UpdateDate"
														}
													}
												],
												"outputs": [
													{
														"referenceName": "dsParquetRaw",
														"type": "DatasetReference",
														"parameters": {
															"NombreFichero": "@concat( item().FileName, '_', formatDateTime(utcnow(), 'yyyyMMdd'),'.', item().Format)"
														}
													}
												]
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "Clean Landing",
						"type": "Delete",
						"state": "Inactive",
						"onInactiveMarkAs": "Succeeded",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "dsParquetRaw",
								"type": "DatasetReference",
								"parameters": {
									"NombreFichero": "*"
								}
							},
							"logStorageSettings": {
								"linkedServiceName": {
									"referenceName": "ls_ADLG2_Bronze_Landing",
									"type": "LinkedServiceReference"
								},
								"path": "mdw/bronze/Landing"
							},
							"enableLogging": true,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-09-16T00:20:34Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/csvConfiguration')]",
				"[concat(variables('workspaceId'), '/datasets/dsParquetRaw')]",
				"[concat(variables('workspaceId'), '/linkedServices/ls_ADLG2_Bronze_Landing')]",
				"[concat(variables('workspaceId'), '/datasets/dsSQLGenerico')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/1 - SqlToLanding_old')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Listado tablas a cargar",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": false,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"dataset": {
								"referenceName": "csvConfiguration",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Listado tablas a cargar",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Listado tablas a cargar').output.value",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "Copiar Tablas de Configuracion",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "SqlServerSource",
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"sink": {
											"type": "ParquetSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "ParquetWriteSettings"
											}
										},
										"enableStaging": false,
										"parallelCopies": 1,
										"dataIntegrationUnits": 4,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "dsSQLGenerico",
											"type": "DatasetReference",
											"parameters": {
												"NombreServidor": {
													"value": "@item().ServerName",
													"type": "Expression"
												},
												"NombreBD": {
													"value": "@item().DataBaseName",
													"type": "Expression"
												},
												"NombreEsquema": {
													"value": "@item().SchemaName",
													"type": "Expression"
												},
												"NombreTabla": {
													"value": "@item().TableName",
													"type": "Expression"
												},
												"FechaActualizacion": {
													"value": "@item().UpdateDate",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "dsParquetRaw",
											"type": "DatasetReference",
											"parameters": {
												"NombreFichero": {
													"value": "@concat( item().FileName, '_', formatDateTime(utcnow(), 'yyyyMMdd'),'.', item().Format)\n",
													"type": "Expression"
												}
											}
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-09-15T16:45:27Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/csvConfiguration')]",
				"[concat(variables('workspaceId'), '/datasets/dsSQLGenerico')]",
				"[concat(variables('workspaceId'), '/datasets/dsParquetRaw')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/2 - BronzeToSilver')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata1').output.childItems",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "Clean Landing",
									"type": "Delete",
									"state": "Inactive",
									"onInactiveMarkAs": "Succeeded",
									"dependsOn": [
										{
											"activity": "LandingToProcessed",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataset": {
											"referenceName": "dsParquetRaw",
											"type": "DatasetReference",
											"parameters": {
												"NombreFichero": {
													"value": "@item().name",
													"type": "Expression"
												}
											}
										},
										"enableLogging": false,
										"storeSettings": {
											"type": "AzureBlobFSReadSettings",
											"recursive": false,
											"enablePartitionDiscovery": false
										}
									}
								},
								{
									"name": "LandingToProcessed",
									"type": "Copy",
									"dependsOn": [
										{
											"activity": "MergeBronzeToSilver",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "ParquetSource",
											"storeSettings": {
												"type": "AzureBlobFSReadSettings",
												"recursive": false,
												"enablePartitionDiscovery": false
											},
											"formatSettings": {
												"type": "ParquetReadSettings"
											}
										},
										"sink": {
											"type": "ParquetSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "ParquetWriteSettings"
											}
										},
										"enableStaging": false,
										"parallelCopies": 1,
										"dataIntegrationUnits": 4,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "dsParquetRaw",
											"type": "DatasetReference",
											"parameters": {
												"NombreFichero": {
													"value": "@item().name",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "dsParquetProcessed",
											"type": "DatasetReference",
											"parameters": {
												"NombreFichero": {
													"value": "@item().name",
													"type": "Expression"
												},
												"NombreCarpeta": {
													"value": "@concat(\n    substring(item().name, 0, indexOf(item().name, '_')), \n    '/', \n    substring(item().name, add(indexOf(item().name, '_'), 1), 4), \n    '/', \n    substring(item().name, add(indexOf(item().name, '_'), 5), 2), \n    '/'\n)\n",
													"type": "Expression"
												}
											}
										}
									]
								},
								{
									"name": "MergeBronzeToSilver",
									"type": "SynapseNotebook",
									"state": "Inactive",
									"onInactiveMarkAs": "Succeeded",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"notebook": {
											"referenceName": "MergeLandingFilesToSilver",
											"type": "NotebookReference"
										},
										"parameters": {
											"data_lake_container": {
												"value": "abfss://mdw@datalake1pgc.dfs.core.windows.net",
												"type": "string"
											},
											"bronze_folder": {
												"value": "bronze/Landing",
												"type": "string"
											},
											"table_name": {
												"value": {
													"value": "@substring(item().name, 0, indexOf(item().name, '_'))",
													"type": "Expression"
												},
												"type": "string"
											},
											"silver_folder": {
												"value": "silver",
												"type": "string"
											},
											"source_wildcard": {
												"value": {
													"value": "@concat(substring(item().name, 0, indexOf(item().name, '_')), '*.parquet')",
													"type": "Expression"
												},
												"type": "string"
											},
											"key_column_str": {
												"value": {
													"value": "@concat('id',substring(item().name, 0, indexOf(item().name, '_')))",
													"type": "Expression"
												},
												"type": "string"
											}
										},
										"snapshot": true,
										"executorSize": "Small",
										"conf": {
											"spark.dynamicAllocation.enabled": false,
											"spark.dynamicAllocation.minExecutors": 2,
											"spark.dynamicAllocation.maxExecutors": 2
										},
										"driverSize": "Small",
										"numExecutors": 2
									}
								}
							]
						}
					},
					{
						"name": "Get Metadata1",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "dsRawEntidades",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "ParquetReadSettings"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/dsRawEntidades')]",
				"[concat(variables('workspaceId'), '/datasets/dsParquetRaw')]",
				"[concat(variables('workspaceId'), '/datasets/dsParquetProcessed')]",
				"[concat(variables('workspaceId'), '/notebooks/MergeLandingFilesToSilver')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/3 - SilverToSCD2')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Lista ficheros Landing",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "dsRawEntidades",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "ParquetReadSettings"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-09-14T15:15:28Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/dsRawEntidades')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/4 - SilverToGold')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Lista ficheros Landing",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "dsRawEntidades",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "ParquetReadSettings"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-09-14T15:17:01Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/dsRawEntidades')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ETL')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "1",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "1 - SqlToLanding",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "3",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "1_copy1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "3 - SilverToSCD2",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "4",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "3",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "4 - SilverToGold",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "1_copy1",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "2 - BronzeToSilver",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-09-15T16:46:15Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/1 - SqlToLanding')]",
				"[concat(variables('workspaceId'), '/pipelines/3 - SilverToSCD2')]",
				"[concat(variables('workspaceId'), '/pipelines/4 - SilverToGold')]",
				"[concat(variables('workspaceId'), '/pipelines/2 - BronzeToSilver')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/csvConfiguration')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_ADLG2_Bronze_Landing",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "ConfiguracionOrigenes.csv",
						"folderPath": "bronze/Configuration",
						"fileSystem": "mdw"
					},
					"columnDelimiter": ";",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "ServerName;DataBaseName;SchemaName;TableName;PathName;FileName;Load",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ls_ADLG2_Bronze_Landing')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dsParquetProcessed')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_ADLG2_Bronze_Landing",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"NombreFichero": {
						"type": "string"
					},
					"NombreCarpeta": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().NombreFichero",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@concat('bronze/Processed/', dataset().NombreCarpeta)",
							"type": "Expression"
						},
						"fileSystem": "mdw"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ls_ADLG2_Bronze_Landing')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dsParquetRaw')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_ADLG2_Bronze_Landing",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"NombreFichero": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().NombreFichero",
							"type": "Expression"
						},
						"folderPath": "bronze/Landing",
						"fileSystem": "mdw"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ls_ADLG2_Bronze_Landing')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dsRawEntidades')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_ADLG2_Bronze_Landing",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "bronze/Landing",
						"fileSystem": "mdw"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ls_ADLG2_Bronze_Landing')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dsSQLGenerico')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_COLI_ERP",
					"type": "LinkedServiceReference",
					"parameters": {
						"NombreServidor": {
							"value": "@dataset().NombreServidor",
							"type": "Expression"
						},
						"NombreBaseDatos": {
							"value": "@dataset().NombreBD",
							"type": "Expression"
						}
					}
				},
				"parameters": {
					"NombreServidor": {
						"type": "string"
					},
					"NombreBD": {
						"type": "string"
					},
					"NombreEsquema": {
						"type": "string"
					},
					"NombreTabla": {
						"type": "string"
					},
					"FechaActualizacion": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "SqlServerTable",
				"schema": [],
				"typeProperties": {
					"schema": {
						"value": "@dataset().NombreEsquema",
						"type": "Expression"
					},
					"table": {
						"value": "@dataset().NombreTabla",
						"type": "Expression"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ls_COLI_ERP')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/asa-tfm-pgc-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('asa-tfm-pgc-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/asa-tfm-pgc-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('asa-tfm-pgc-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ls_ADLG2_Bronze_Landing')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('ls_ADLG2_Bronze_Landing_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('ls_ADLG2_Bronze_Landing_accountKey')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ls_COLI_ERP')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"NombreServidor": {
						"type": "string"
					},
					"NombreBaseDatos": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "SqlServer",
				"typeProperties": {
					"server": "[parameters('ls_COLI_ERP_properties_typeProperties_server')]",
					"database": "[parameters('ls_COLI_ERP_properties_typeProperties_database')]",
					"encrypt": "mandatory",
					"trustServerCertificate": true,
					"authenticationType": "SQL",
					"userName": "[parameters('ls_COLI_ERP_properties_typeProperties_userName')]",
					"password": {
						"type": "SecureString",
						"value": "[parameters('ls_COLI_ERP_password')]"
					}
				},
				"connectVia": {
					"referenceName": "IR-Coli-ERP",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/IR-Coli-ERP')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/IR-Coli-ERP')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "SelfHosted",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Script Dimensiones Silver')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE  or ALTER view [dbo].[vw_dim_Fechas] AS \nSELECT \n    idFechas,\n    ClaveFecha,\n    Fecha,\n    Mes,\n    NumeroMes,\n    AÃ±o,\n    NumeroSemana,\n    DiaSemana,\n    NumeroDiaSemana,\n    DiaAÃ±o,\n    Trimestre,\n    Cuatrimestre,\n    CASE WHEN Cuatrimestre IN (1,2) THEN 1\n         WHEN Cuatrimestre IN (2,4) THEN 2\n         ELSE -1 END AS Semestre,\n    fechaActualizacion\nFROM \n    Silver.dbo.fechas",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SilverlessSTG",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/MergeLandingFilesToSilver')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "120f7844-fea9-4902-bb56-40ddce8321b5"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"# # path of the data lake container (bronze and silver for this example)\r\n",
							"# data_lake_container = 'abfss://etl@datalakefrancepgc.dfs.core.windows.net'\r\n",
							"# # The ingestion folder where your parquet file are located\r\n",
							"# bronze_folder = 'bronze/Landing'\r\n",
							"# # The silver folder where your Delta Tables will be stored\r\n",
							"# silver_folder = 'silver'\r\n",
							"# # The name of the table\r\n",
							"# table_name = 'talla'\r\n",
							"# # The wildcard filter used within the bronze folder to find files\r\n",
							"# source_wildcard = 'talla*.parquet'\r\n",
							"# # A comma separated string of one or more key columns (for the merge)\r\n",
							"# key_columns_str = 'idTalla'"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"**Carga de ficheros parquet Landing sobre tablas Delta capa Silver**"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Import modules\r\n",
							"from delta.tables import DeltaTable\r\n",
							"from delta.tables import *\r\n",
							"from pyspark.sql.functions import when, lit, current_date, date_format\r\n",
							"#from pyspark.dbutils import DBUtils\r\n",
							"from pyspark.sql import SparkSession\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# table_name = \"silver.fechas\"  # Reemplaza con el nombre de tu tabla\r\n",
							"\r\n",
							"# # Ejecutar el comando para eliminar la tabla\r\n",
							"# spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")\r\n",
							"\r\n",
							"# source_path = data_lake_container + '/' + bronze_folder + '/' + source_wildcard\r\n",
							"\r\n",
							"# Determine path of Delta Lake Table \r\n",
							"#delta_table_path = data_lake_container + '/' + silver_folder + '/' + table_name\r\n",
							"\r\n",
							"#spark.sql(f\"DROP TABLE IF EXISTS silver.fecha\")"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Prueba::\r\n",
							"\r\n",
							"\r\n",
							"# # Crear SparkSession\r\n",
							"# spark = SparkSession.builder \\\r\n",
							"#     .appName(\"Delta Merge Example\") \\\r\n",
							"#     .config(\"spark.sql.extensions\", \"delta.sql.DeltaSparkSessionExtensions\") \\\r\n",
							"#     .config(\"spark.sql.catalog.spark_catalog\", \"delta.catalog.DeltaCatalog\") \\\r\n",
							"#     .getOrCreate()\r\n",
							"\r\n",
							"# Supongamos que tienes las variables necesarias\r\n",
							"# Fecha actual en formato yyyymmdd\r\n",
							"fecha_delta = date_format(current_date(), 'yyyyMMdd')\r\n",
							"fecha_delta = '20241008'\r\n",
							"# Convert comma separated string with keys to array\r\n",
							"key_columns = key_columns_str.split(',')\r\n",
							"\r\n",
							"# Convert array with keys to where-clause for merge statement\r\n",
							"conditions_list = [f\"existing.{key}=updates.{key}\" for key in key_columns]\r\n",
							"\r\n",
							"# Determine path of source files from ingest layer\r\n",
							"source_path = data_lake_container + '/' + bronze_folder + '/' + source_wildcard\r\n",
							"\r\n",
							"# Determine path of Delta Lake Table \r\n",
							"delta_table_path = data_lake_container + '/' + silver_folder + '/' + table_name\r\n",
							"\r\n",
							"# Read file(s) in spark data frame\r\n",
							"sdf = spark.read.format('parquet').option(\"recursiveFileLookup\", \"true\").load(source_path)\r\n",
							"\r\n",
							"# Eliminar las columnas que no se desean\r\n",
							"sdf = sdf.drop(\"fechaActualizacion\", \"pipelineID\")\r\n",
							"\r\n",
							"# Check if the Delta Table exists\r\n",
							"if DeltaTable.isDeltaTable(spark, delta_table_path):\r\n",
							"    # Read the existing Delta Table\r\n",
							"    delta_table = DeltaTable.forPath(spark, delta_table_path)\r\n",
							"\r\n",
							"    # Get the schema of the existing Delta table\r\n",
							"    existing_columns = delta_table.toDF().columns\r\n",
							"    \r\n",
							"    # AÃ±adir columna fechaDelta al DataFrame\r\n",
							"    sdf = sdf.withColumn(\"fechaDelta\", lit(fecha_delta))\r\n",
							"\r\n",
							"    # Crear el conjunto de actualizaciones excluyendo 'fechaCarga'\r\n",
							"    update_set = {f\"existing.{col}\": f\"updates.{col}\" for col in existing_columns if col != 'fechaCarga'}\r\n",
							"\r\n",
							"    # Merge new data into existing table\r\n",
							"    delta_table.alias(\"existing\").merge(\r\n",
							"        source=sdf.alias(\"updates\"),\r\n",
							"        condition=\" AND \".join(conditions_list)\r\n",
							"    ).whenMatchedUpdate(\r\n",
							"        #condition=\" OR \".join([f\"existing.{col} != updates.{col}\" for col in existing_columns if col not in ('fechaCarga', 'fechaDelta')]),\r\n",
							"        set={\r\n",
							"            \"fechaCarga\": \"updates.fechaCarga\",  # Usar fechaCarga del DataFrame\r\n",
							"            \"fechaDelta\": \"updates.fechaDelta\",  # Usar fechaDelta del DataFrame\r\n",
							"            **{f\"existing.{col}\": f\"updates.{col}\" for col in existing_columns if col not in ('fechaCarga', 'fechaDelta')}  # Incluir otros campos\r\n",
							"        }\r\n",
							"    ).whenNotMatchedInsert(\r\n",
							"        values={\r\n",
							"            \"fechaCarga\": \"updates.fechaCarga\",  # Usar fechaCarga del DataFrame\r\n",
							"            \"fechaDelta\": fecha_delta,  # Establecer fechaDelta al insertar\r\n",
							"            **{f\"{col}\": f\"updates.{col}\" for col in existing_columns if col not in ('fechaCarga', 'fechaDelta')}  # Incluir otros campos\r\n",
							"        }\r\n",
							"    ).execute()\r\n",
							"else:\r\n",
							"    # Crear nueva tabla Delta con nuevos datos, incluyendo la columna fechaDelta\r\n",
							"    sdf = sdf.withColumn(\"fechaCarga\", sdf.fechaCarga)  # Mantener fechaCarga del DataFrame\r\n",
							"    sdf = sdf.withColumn(\"fechaDelta\", lit(fecha_delta))  # Establecer fechaDelta al crear la tabla\r\n",
							"    sdf.write.format('delta').save(delta_table_path)\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# ### Prueba ori::\r\n",
							"# from pyspark.sql import SparkSession\r\n",
							"# from pyspark.sql.functions import current_date, date_format\r\n",
							"# from delta.tables import *\r\n",
							"\r\n",
							"# # # Crear SparkSession\r\n",
							"# # spark = SparkSession.builder \\\r\n",
							"# #     .appName(\"Delta Merge Example\") \\\r\n",
							"# #     .config(\"spark.sql.extensions\", \"delta.sql.DeltaSparkSessionExtensions\") \\\r\n",
							"# #     .config(\"spark.sql.catalog.spark_catalog\", \"delta.catalog.DeltaCatalog\") \\\r\n",
							"# #     .getOrCreate()\r\n",
							"\r\n",
							"# # Supongamos que tienes las variables necesarias\r\n",
							"# # Fecha actual en formato yyyymmdd\r\n",
							"# fecha_delta = date_format(current_date(), 'yyyyMMdd')\r\n",
							"# fecha_delta = '20241007'\r\n",
							"# # Convert comma separated string with keys to array\r\n",
							"# key_columns = key_columns_str.split(',')\r\n",
							"\r\n",
							"# # Convert array with keys to where-clause for merge statement\r\n",
							"# conditions_list = [f\"existing.{key}=updates.{key}\" for key in key_columns]\r\n",
							"\r\n",
							"# # Determine path of source files from ingest layer\r\n",
							"# source_path = data_lake_container + '/' + bronze_folder + '/' + source_wildcard\r\n",
							"\r\n",
							"# # Determine path of Delta Lake Table \r\n",
							"# delta_table_path = data_lake_container + '/' + silver_folder + '/' + table_name\r\n",
							"\r\n",
							"# # Read file(s) in spark data frame\r\n",
							"# sdf = spark.read.format('parquet').option(\"recursiveFileLookup\", \"true\").load(source_path)\r\n",
							"\r\n",
							"# # Eliminar las columnas que no se desean\r\n",
							"# sdf = sdf.drop(\"fechaActualizacion\", \"pipelineID\")\r\n",
							"\r\n",
							"# # Check if the Delta Table exists\r\n",
							"# if DeltaTable.isDeltaTable(spark, delta_table_path):\r\n",
							"#     # Read the existing Delta Table\r\n",
							"#     delta_table = DeltaTable.forPath(spark, delta_table_path)\r\n",
							"\r\n",
							"#     # Get the schema of the existing Delta table\r\n",
							"#     existing_columns = delta_table.toDF().columns\r\n",
							"    \r\n",
							"#     # AÃ±adir columna fechaDelta al DataFrame\r\n",
							"#     sdf = sdf.withColumn(\"fechaDelta\", lit(fecha_delta))\r\n",
							"\r\n",
							"#     # Crear el conjunto de actualizaciones excluyendo 'fechaCarga'\r\n",
							"#     update_set = {f\"existing.{col}\": f\"updates.{col}\" for col in existing_columns if col != 'fechaCarga'}\r\n",
							"\r\n",
							"#     # Merge new data into existing table\r\n",
							"#     delta_table.alias(\"existing\").merge(\r\n",
							"#         source=sdf.alias(\"updates\"),\r\n",
							"#         condition=\" AND \".join(conditions_list)\r\n",
							"#     ).whenMatchedUpdate(\r\n",
							"#         set={\r\n",
							"#             \"fechaCarga\": \"updates.fechaCarga\",  # Usar fechaCarga del DataFrame\r\n",
							"#             \"fechaDelta\": \"updates.fechaDelta\",  # Usar fechaDelta del DataFrame\r\n",
							"#             **{f\"existing.{col}\": f\"updates.{col}\" for col in existing_columns if col not in ('fechaCarga', 'fechaDelta')}  # Incluir otros campos\r\n",
							"#         }\r\n",
							"#     ).whenNotMatchedInsert(\r\n",
							"#         values={\r\n",
							"#             \"fechaCarga\": \"updates.fechaCarga\",  # Usar fechaCarga del DataFrame\r\n",
							"#             \"fechaDelta\": fecha_delta,  # Establecer fechaDelta al insertar\r\n",
							"#             **{f\"{col}\": f\"updates.{col}\" for col in existing_columns if col not in ('fechaCarga', 'fechaDelta')}  # Incluir otros campos\r\n",
							"#         }\r\n",
							"#     ).execute()\r\n",
							"# else:\r\n",
							"#     # Crear nueva tabla Delta con nuevos datos, incluyendo la columna fechaDelta\r\n",
							"#     sdf = sdf.withColumn(\"fechaCarga\", sdf.fechaCarga)  # Mantener fechaCarga del DataFrame\r\n",
							"#     sdf = sdf.withColumn(\"fechaDelta\", lit(fecha_delta))  # Establecer fechaDelta al crear la tabla\r\n",
							"#     sdf.write.format('delta').save(delta_table_path)\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Adding the Delta Table to the Delta Database for easy querying in other notebooks or scripts within Synapse.\r\n",
							"spark.sql(f'CREATE TABLE IF NOT EXISTS Silver.{table_name} USING DELTA LOCATION \\'{delta_table_path}\\'')\r\n",
							" \r\n",
							"# Spark SQL version\r\n",
							"# CREATE TABLE Silver.MyTable\r\n",
							"# USING DELTA\r\n",
							"#LOCATION 'abfss://yourcontainer@yourdatalake.dfs.core.windows.net/Silver/MyTable'"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"**Actualizar CSV Configuracion**"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# cuenta =  'datalake1pgc'\r\n",
							"# contendor = 'mdw'\r\n",
							"# archivo = '/bronze/Configuration/ConfiguracionOrigenes.csv'\r\n",
							"\r\n",
							"# #ruta = 'abfss://%s@%s.dfs.core.windows.net/%s' % (contendor, cuenta, archivo)\r\n",
							"# ruta = f'abfss://{contendor}@{cuenta}.dfs.core.windows.net/{archivo}'\r\n",
							"# # Leer CSV\r\n",
							"# #print(ruta)\r\n",
							"# df = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").csv(ruta)\r\n",
							"# #Generamos fecha en formato 'yyyyMMdd'\r\n",
							"# fecha_actual = date_format(current_date(), 'yyyy-MM-dd')\r\n",
							"# fecha_actual = '2022-01-17'\r\n",
							"# # Modificar CSV\r\n",
							"# df_modificado = df.withColumn(\r\n",
							"#     \"UpdateDate\",\r\n",
							"#     when(df[\"Filename\"] == table_name, fecha_actual).otherwise(df[\"UpdateDate\"])\r\n",
							"# )\r\n",
							"# # Sobreescrir CSV\r\n",
							"# #df_modificado.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(ruta)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#df_modificado.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(ruta)\r\n",
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Silver')]",
			"type": "Microsoft.Synapse/workspaces/databases",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"Ddls": [
					{
						"ActionType": "CREATE",
						"OldEntity": null,
						"NewEntity": {
							"Name": "Silver",
							"EntityType": "DATABASE",
							"Origin": {
								"Type": "SPARK"
							},
							"Properties": {
								"IsSyMSCDMDatabase": true
							},
							"Source": {
								"Provider": "ADLS",
								"Location": "abfss://mdw@datalake1pgc.dfs.core.windows.net/silver",
								"Properties": {
									"FormatType": "parquet",
									"LinkedServiceName": "ls_ADLG2_Bronze_Landing"
								}
							}
						},
						"Source": {
							"Type": "SPARK"
						}
					}
				]
			},
			"dependsOn": []
		}
	]
}